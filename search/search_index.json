{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>Welcome to Wiki Pages of Information Technology and Communication Sciences at Tampere University.</p> <p>This wiki is meant to be a tool for personnel of our department, supporting research and teaching needs. You (yes you!) can contribute content to this wiki and help us building the common crowdsourced knowledge database.</p>"},{"location":"#university-bureaucracy","title":"University Bureaucracy","text":"<ul> <li>Contracts and salary</li> <li>MSc thesis</li> <li>PhD thesis</li> <li>CS Curricula</li> </ul>"},{"location":"#technical-notes","title":"Technical Notes","text":"<ul> <li>How to set up Remote Access</li> <li>How to install TUNI VPN</li> <li>TUNI TCSC Cluster</li> <li>Distributed data parallel training using Pytorch on the multiple nodes of CSC and Narvi</li> <li>Version control</li> <li>Wireless connections</li> <li>SAUNA Machines Best Practices, Tips and Tricks</li> <li>Custom LUMI Python Environments</li> </ul>"},{"location":"#meta","title":"Meta","text":"<ul> <li>How to contrubute to the Wiki</li> </ul>"},{"location":"#links","title":"Links","text":"<ul> <li>Computer Vision Group</li> <li>Tampere University</li> </ul>"},{"location":"#outdated","title":"Outdated","text":"<p>Information not valid for TUNI users, but can still be useful knowledge.</p> <ul> <li>TUNI Narvi Cluster</li> </ul>"},{"location":"Meta/how-to-contribute/","title":"How to Contribute to This Wiki?","text":"<p>This Wiki \ud83d\udcd6 is a crowdsourced base of knowledge accumulated by generations of current and ex research assistants, students, faculty members, friends, and other personnel. It is \"whatever\" annoying you don't remember after two months anymore or what frequently someone asks.</p> <p>The knowledge is expected to be contributed via Markdown files (<code>.md</code>) and submitted as Pull Requests to TUNI-ITC/wiki. This guide describes this process step-by-step.</p> <p>There are two options on how to contribute to Wiki:</p> <ol> <li>Do-it-yourself \ud83d\udc4d: you are following this guide and submitting the Pull Request.</li> <li>Ask somebody: for instance, you are not familiar with <code>git</code> and don't want to discover its beauty, then, create an Issue in TUNI-ITC/wiki and share a <code>.md</code> file with us. Here are the guide and an online Markdown editor.</li> </ol> <p>What Can I Contribute?</p> <p>Anything! Style, spelling, new knowledge, Wiki's engine. Anything, ok? \ud83e\udd17</p>"},{"location":"Meta/how-to-contribute/#what-should-i-do","title":"What Should I Do?","text":"I already have an old fork on my GitHub <p>A good pratice is to have an even (up-to-date) fork with the upstream repo (<code>TUNI-ITC/wiki</code>) before you form a pull request. Otherwise, you may purpose an edit to the old content that is no longer there.</p> <p>Of course, the easiest way to sync a fork (and the last resort measure if something went wrong) is to delete the fork from your GitHub account and fork TUNI-ITC/wiki again. A less barbaric approach is to sync it. Here is how to do it.</p> <p>If you already made some new contributions, make sure to backup them to avoid issues. You may also want to remove the fork from your local machine and clone the fork again from your profile on GitHub.</p> <p>Synchronizing a fork is a simple procedure but requires you to run several lines in your terminal: <pre><code># (this line is for the first time only) Add the upsteam to your git folder.\ngit remote add upstream https://github.com/TUNI-ITC/wiki.git\ngit fetch upstream\ngit checkout main\n# WARNING: this erases all differences between upstream and your local version\ngit reset --hard upstream/main\n# pushes the changes to your fork on GitHub\ngit push origin main --force\n</code></pre></p> <p>The pipeline boils down to these several steps which should be familiar to anyone who worked with an open-source project on some sort of Hub \ud83e\udd13 (GitHub, Bitbucket, GitLab, and such):</p> <ol> <li>Create an Issue (skip if feeling lazy or playing like a bad boy)</li> <li>Fork &amp; Clone</li> <li>Add/Change</li> <li>Push to the Fork</li> <li>Create a Pull Request</li> </ol>"},{"location":"Meta/how-to-contribute/#1-create-an-issue","title":"1. Create an Issue","text":"<p>This is completely optional and we would like to see an issue just to track the progress and maybe suggest where (which section) to put your knowledge or help you with something.</p>"},{"location":"Meta/how-to-contribute/#2-fork-clone","title":"2. Fork &amp; Clone","text":"<p>You can edit directly through the GitHub web page (\"Add File\" and \"Edit\" button) or do it locally on your computer. We recommend learning to do it the hard way by forking and cloning it manually you will benefit from this knowledge in your career, otherwise skip this step.</p> <p>Fork means that you make a personal copy of this wiki - note that anyone can do that and it does not mess the main branch! To do that go to TUNI-ITC/wiki and press the top-right button Fork - if you don't have a Github account yet, you need to make one.</p> <p>After that, you should have the forked repo somewhere in your account, e.g., <code>github.com/&lt;MY_ACCOUNT&gt;/wiki/</code>.</p> <p>To clone your fork locally, in terminal type: <pre><code>git clone https://github.com/&lt;MY_ACCOUNT&gt;/wiki/\n</code></pre> and it's done!</p>"},{"location":"Meta/how-to-contribute/#3-addchange","title":"3. Add/Change","text":"<p>You may freely edit an existing file or create new, e.g., <code>how-to-select-a-coffee-in-a-finnish-supermarket.md</code>. Here are the guide and an online Markdown editor for you to play with.</p> <p>We are using Material Theme for MkDocs. Hence, you may also propose to add more functionality to our wiki. Check out the manuals of both to see what else we can add.</p> Can I check locally how it will look? <p>Sure thing! You will only need to install the <code>mkdocs-material</code> python package using either <pre><code>pip install mkdocs-material\n</code></pre> or (Ubuntu preferred) <pre><code>sudo apt install mkdocs-material\n</code></pre> Once done, you can start a preview server locally <pre><code>cd /path/to/wiki\nmkdocs serve\n</code></pre> After, just type <code>localhost:8000</code> in your browser.</p> <p>See more in the original documentation.</p>"},{"location":"Meta/how-to-contribute/#4-push-to-the-changes-to-the-fork","title":"4. Push to the Changes to the Fork","text":"<p>Commit your changes! You know how, right?</p> Ok, here is how <pre><code># it will print the modifications were made compared to last commit\ngit status\n# this will `stage` you changes\ngit add how-to-do-something.md\n# this will commit the staged changes\n# (it may ask you to configure git if you are doing to for the first time)\ngit commit -m \"added how-to-do-something.md\"\ngit push\n</code></pre>"},{"location":"Meta/how-to-contribute/#5-create-a-pull-request","title":"5. Create a Pull Request","text":"<p>Open the page with your fork on GitHub: <code>github.com/&lt;MY_ACCOUNT&gt;/wiki/</code>. At this point, you should be able to find the changes you made in your fork. Somewhere at the top, you will be asked if you want to make a Pull Request and that your branch is ahead of the <code>main</code> by some commits. Make the request, by adding comments, title, and check that you are proposing the files you expect and submit it. Someone will review and accept it. That's it!</p> <p>Note, once the PR is submitted it cannot be deleted even by the moderators.</p>"},{"location":"Technical-Notes/Distributed_dataparallel_pytorch/","title":"Distributed data parallel training using Pytorch on the multiple nodes of CSC and Narvi clusters","text":""},{"location":"Technical-Notes/Distributed_dataparallel_pytorch/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Motivation</li> <li>Outline</li> <li>Setting up a PyTorch model without DistributedDataParallel</li> <li>Setting up the same model with DistributedDataParallel</li> <li>DistributedDataParallel as a Batch job in the servers</li> <li>Tips and Tricks</li> <li>Acknowledgements</li> </ol>"},{"location":"Technical-Notes/Distributed_dataparallel_pytorch/#motivation","title":"Motivation","text":"<p>Training a Deep Neural Network (DNNs) is notoriously time-consuming especially nowadays when they are getting bigger to get better. To reduce the training time, we mostly train it on the multiple gpus within a single node or across different nodes. This tutorial is focused on the latter where multiple nodes are utilised using PyTorch. Although there are many tutorials available on the web including one from the PyTorch, they are not self-sufficient in explaining some of the key issues like how to run the code, how to save checkpoints, or how to create a batch script for this in the severs. I have given a starter kit here which addresses these issues and can be helpful to students of our university in setting up their first multi-gpu training in the servers like CSC-Puhti or Narvi.</p>"},{"location":"Technical-Notes/Distributed_dataparallel_pytorch/#outline","title":"Outline","text":"<p>PyTorch mostly provides two functions namely <code>nn.DataParallel</code> and <code>nn.DistributedDataParallel</code> to use multiple gpus in a single node and multiple nodes during the training respectively. However, it is recommended by PyTorch to use <code>nn.DistributedDataParallel</code> even in the single node to train faster than the <code>nn.DataParallel</code>. For more details, I would recommend reading the PyTorch docs. This tutorial assumes that the reader is familiar with the DNNs training using PyTorch and basic operations on the gpu-servers of our university.</p>"},{"location":"Technical-Notes/Distributed_dataparallel_pytorch/#setting-up-a-pytorch-model-without-distributeddataparallel","title":"Setting up a PyTorch model without DistributedDataParallel","text":"<p>I have considered a simple Auto-Encoder (AE) model for demonstration where the inputs are images of digits from MNIST data-set. Just to be clear, AE takes images as input and encodes it to a much smaller dimension w.r.t its inputs and then try to reconstruct the images back from those smaller dimensions. It can be considered as a process of compression and decompression. We train the network to learn this smaller dimension such that the reconstructed image is very close to input. Let's begin by defining the network structure.</p> <p><pre><code>import torch\nimport torch.nn as nn\nimport torchvision\nfrom argparse import ArgumentParser\n\nclass AE(nn.Module):\n    def __init__(self, **kwargs):\n        super().__init__()\n\n        self.net = nn.Sequential(\n            nn.Linear(in_features=kwargs[\"input_shape\"], out_features=128),\n            nn.ReLU(inplace=True),\n            # small dimension\n            nn.Linear(in_features=128, out_features=128),\n            nn.ReLU(inplace=True),\n            nn.Linear(in_features=128, out_features=128),\n            nn.ReLU(inplace=True),\n            # Recconstruction of input\n            nn.Linear(in_features=128, out_features=kwargs[\"input_shape\"]),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, features):\n        reconstructed = self.net(features)\n        return reconstructed\n</code></pre> Lets create a <code>train()</code> function where we load the MNIST data-set and this can easily be done from the <code>torchvision.dataset</code> library as follows <pre><code>def train(gpu, args):\n    transform = torchvision.transforms.Compose([\n        torchvision.transforms.ToTensor()\n    ])\n\n    train_dataset = torchvision.datasets.MNIST(\n        root=\"~/mnist_dataset\", train=True, transform=transform, download=True\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=128, shuffle=True, num_workers=4,\n        pin_memory=True\n    )\n</code></pre> Transfer the model to the GPU now and declare the optimiser and loss criterion for the training process. <pre><code>def train(gpu, args):\n    transform = torchvision.transforms.Compose([\n        torchvision.transforms.ToTensor()\n    ])\n\n    train_dataset = torchvision.datasets.MNIST(\n        root=\"./mnist_dataset\", train=True, transform=transform, download=True\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=128, shuffle=True, num_workers=4,\n        pin_memory=True\n    )\n\n    # load the model to the specified device, gpu-0 in our case\n    model = AE(input_shape=784).cuda(gpu)\n    # create an optimizer object\n    # Adam optimizer with learning rate 1e-3\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    # Loss function\n    criterion = nn.MSELoss()\n</code></pre> Now wrap everything in the training function and start training</p> <p><pre><code>def train(gpu, args):\n    transform = torchvision.transforms.Compose([\n        torchvision.transforms.ToTensor()\n    ])\n\n    train_dataset = torchvision.datasets.MNIST(\n        root=\"./mnist_dataset\", train=True, transform=transform, download=True\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=128, shuffle=True, num_workers=4,\n        pin_memory=True\n    )\n\n    # load the model to the specified device, gpu-0 in our case\n    model = AE(input_shape=784).cuda(gpu)\n    # create an optimizer object\n    # Adam optimizer with learning rate 1e-3\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    # Loss function\n    criterion = nn.MSELoss()\n\n    for epoch in range(args.epochs):\n        loss = 0\n        for batch_features, _ in train_loader:\n            # reshape mini-batch data to [N, 784] matrix\n            # load it to the active device\n            batch_features = batch_features.view(-1, 784).cuda(gpu)\n\n            # reset the gradients back to zero\n            # PyTorch accumulates gradients on subsequent backward passes\n            optimizer.zero_grad()\n\n            # compute reconstructions\n            outputs = model(batch_features)\n\n            # compute training reconstruction loss\n            train_loss = criterion(outputs, batch_features)\n\n            # compute accumulated gradients\n            train_loss.backward()\n            # pe-rform parameter update based on current gradients\n            optimizer.step()\n\n            # add the mini-batch training loss to epoch loss\n            loss += train_loss.item()\n\n            # compute the epoch training loss\n        loss = loss / len(train_loader)\n\n        # display the epoch training loss\n        print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch+1, args.epochs, loss))\n</code></pre> Now lets finish this code with a <code>main()</code> function that calls the train function and defines the required arguments. <pre><code>def main():\n    parser = ArgumentParser()\n    parser.add_argument('--ngpus', default=1, type=int,\n                        help='number of gpus per node')\n\n    parser.add_argument('--epochs', default=2, type=int, metavar='N',\n                        help='number of total epochs to run')\n    args = parser.parse_args()\n    train(0, args)\n\nif __name__ == '__main__':\n    main()\n</code></pre></p>"},{"location":"Technical-Notes/Distributed_dataparallel_pytorch/#setting-up-the-same-model-with-distributeddataparallel","title":"Setting up the same model with DistributedDataParallel","text":"<p>With the multiprocessing, we will run our training script in each node separately and ask PyTorch to handle the synchronisation between them. It makes sure that in each iteration, the same network weights are present in every node but use different data for the forward pass. Then the gradients are accumulated from every node to calculate the change in weights which will be sent to each node for the update. In short, the same network operates on different data in different nodes in parallel to make things faster. To let this internal communication happen between the nodes, we need few information to setup the DistributedParallel environment such as 1. how many nodes we are using, 2. what is the ip-address of the master node and 3. The number of gpus in a single node. I have changed the order of the above code to make it more understandable. We will first start from the <code>main</code> function by defining all the necessary variables.</p> <ul> <li>A single node can be understood as a single computer with its own gpus and cpus. Here we need multiple of such computers. One thing to remember is that these nodes should be connected to each other. In the servers, they are always connected to each other so we can use it without any problems. In the script, we need to mention the ip-address and port of one of the nodes (we call it the master node) so that all other nodes can be connected to that automatically when we start the script in those nodes.</li> </ul> <pre><code>import torch\nimport torch.nn as nn\nimport torchvision\nimport torch.multiprocessing as mp\nimport torch.distributed as dist\nfrom argparse import ArgumentParser\nimport os\n\nif __name__ == \"__main__\":\n\n    parser = ArgumentParser()\n    parser.add_argument('--nodes', default=1, type=int)\n    parser.add_argument('--local_ranks', default=0, type=int,\n                        help=\"Node's order number in [0, num_of_nodes-1]\")\n    parser.add_argument('--ip_adress', type=str, required=True,\n                        help='ip address of the host node')\n    parser.add_argument(\"--checkpoint\", default=None,\n                        help=\"path to checkpoint to restore\")\n    parser.add_argument('--ngpus', default=1, type=int,\n                        help='number of gpus per node')\n    parser.add_argument('--epochs', default=2, type=int, metavar='N',\n                        help='number of total epochs to run')\n\n    args = parser.parse_args()\n    # Total number of gpus availabe to us.\n    args.world_size = args.ngpu * args.nodes\n    # add the ip address to the environment variable so it can be easily avialbale\n    os.environ['MASTER_ADDR'] = args.ip_adress\n    print(\"ip_adress is\", args.ip_adress)\n    os.environ['MASTER_PORT'] = '8888'\n    os.environ['WORLD_SIZE'] = str(args.world_size)\n    # nprocs: number of process which is equal to args.ngpu here\n    mp.spawn(train, nprocs=args.ngpus, args=(args,))\n</code></pre> <ul> <li>You can imagine the <code>local_rank</code> as an unique number associated to each node starting from zero to number of nodes-1. We assign zero rank to the node whose ip-address is passed to the <code>main()</code> and we start the script first on that node. Further, we are going use this number to calculate one more rank for each gpu in that node.</li> <li>Instead of calling the <code>train</code> function once, we spawn <code>args.ngpus</code> processes in each node to run <code>args.ngpus</code> instances of <code>train</code> function in parallel.</li> </ul> <p>Now lets define the function <code>train</code> that can handle these multiple processes.</p> <pre><code>def train(gpu, args):\n\n    args.gpu = gpu\n    print('gpu:',gpu)\n    # rank calculation for each process per gpu so that they can be identified uniquely.\n    rank = args.local_ranks * args.ngpus + gpu\n    print('rank:',rank)\n    # Boilerplate code to initialize the parallel prccess.\n    # It looks for ip-address and port which we have set as environ variable.\n    # If you don't want to set it in the main then you can pass it by replacing\n    # the init_method as ='tcp://&lt;ip-address&gt;:&lt;port&gt;' after the backend.\n    # More useful information can be found in\n    # https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html\n\n    dist.init_process_group(\n        backend='nccl',\n        init_method='env://',\n        world_size=args.world_size,\n        rank=rank\n    )\n    torch.manual_seed(0)\n    # start from the same randomness in different nodes. If you don't set it\n    # then networks can have different weights in different nodes when the\n    # training starts. We want exact copy of same network in all the nodes.\n    # Then it will progress from there.\n\n    # set the gpu for each processes\n    torch.cuda.set_device(args.gpu)\n\n\n    transform = torchvision.transforms.Compose([\n        torchvision.transforms.ToTensor()\n    ])\n\n    train_dataset = torchvision.datasets.MNIST(\n        root=\"~/mnist_dataset\", train=True, transform=transform, download=True\n    )\n    # Ensures that each process gets differnt data from the batch.\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset, num_replicas=args.world_size, rank=rank\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        # calculate the batch size for each process in the node.\n        batch_size=int(128/args.ngpus),\n        shuffle=(train_sampler is None),\n        num_workers=4,\n        pin_memory=True,\n        sampler=train_sampler\n    )\n</code></pre> <ul> <li>As we are going to submit the training script to each node separately, we need to set a random seed to fix the randomness involved in the code. For example, in the very first iteration the network weights will start from the same random weights (seed=0) in the different nodes. Then PyTorch will handle the synchronisation and at the end of training, we will have the same network weights in each node.</li> <li><code>train_sampler</code>, <code>manual_seed</code> and <code>modified batch size in the dataloader</code> are important steps to remember while setting this up.</li> </ul> <p>Finally, wrap the model as DistributedDataParallel and start the training. <pre><code>def train(gpu, args):\n    args.gpu = gpu\n    print('gpu:',gpu)\n    rank = args.local_ranks * args.ngpus + gpu\n    # rank calculation for each process per gpu so that they can be\n    # identified uniquely.\n    print('rank:',rank)\n    # Boilerplate code to initialise the parallel process.\n    # It looks for ip-address and port which we have set as environ variable.\n    # If you don't want to set it in the main then you can pass it by replacing\n    # the init_method as ='tcp://&lt;ip-address&gt;:&lt;port&gt;' after the backend.\n    # More useful information can be found in\n    # https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html\n\n    dist.init_process_group(\n        backend='nccl',\n        init_method='env://',\n        world_size=args.world_size,\n        rank=rank\n    )\n    torch.manual_seed(0)\n    # start from the same randomness in different nodes.\n    # If you don't set it then networks can have different weights in different\n    # nodes when the training starts. We want exact copy of same network in all\n    # the nodes. Then it will progress form there.\n\n    # set the gpu for each processes\n    torch.cuda.set_device(args.gpu)\n\n\n    transform = torchvision.transforms.Compose([\n        torchvision.transforms.ToTensor()\n    ])\n\n    train_dataset = torchvision.datasets.MNIST(\n        root=\"./mnist_dataset\", train=True, transform=transform, download=True\n    )\n    # Ensures that each process gets differnt data from the batch.\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset, num_replicas=args.world_size, rank=rank\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        # calculate the batch size for each process in the node.\n        batch_size=int(128/args.ngpus),\n        shuffle=(train_sampler is None),\n        num_workers=4,\n        pin_memory=True,\n        sampler=train_sampler\n    )\n\n\n    # load the model to the specified device, gpu-0 in our case\n    model = AE(input_shape=784).cuda(args.gpus)\n    model = torch.nn.parallel.DistributedDataParallel(\n        model_sync, device_ids=[args.gpu], find_unused_parameters=True\n    )\n    # create an optimizer object\n    # Adam optimizer with learning rate 1e-3\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    # Loss function\n    criterion = nn.MSELoss()\n\n    for epoch in range(args.epochs):\n        loss = 0\n        for batch_features, _ in train_loader:\n            # reshape mini-batch data to [N, 784] matrix\n            # load it to the active device\n            batch_features = batch_features.view(-1, 784).cuda(args.gpus)\n\n            # reset the gradients back to zero\n            # PyTorch accumulates gradients on subsequent backward passes\n            optimizer.zero_grad()\n\n            # compute reconstructions\n            outputs = model(batch_features)\n\n            # compute training reconstruction loss\n            train_loss = criterion(outputs, batch_features)\n\n            # compute accumulated gradients\n            train_loss.backward()\n\n            # perform parameter update based on current gradients\n            optimizer.step()\n\n            # add the mini-batch training loss to epoch loss\n            loss += train_loss.item()\n\n        # compute the epoch training loss\n        loss = loss / len(train_loader)\n\n        # display the epoch training loss\n        print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch+1, args.epochs, loss))\n        if rank == 0:\n            dict_model = {\n                'state_dict': model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'epoch': args.epochs,\n            }\n            torch.save(dict_model, './model.pth')\n</code></pre></p> <ul> <li>Save the model only when the rank is zero because all the models are the same. We only need to save one copy of the model. If we are not careful here then all the processes will try to save weights and can corrupt the weights.</li> </ul> <p>Save the script as <code>train.py</code> in the CSC or Narvi server and submit an interactive job with two gpu nodes (Lets quickly test it on <code>gputest</code> node as <code>srun --pty --account=Project_** --nodes=2 -p gputest --gres=gpu:v100:1,nvme:100 -t 00:15:00 --mem-per-cpu=20000 --ntasks-per-node=1 --cpus-per-task=8 /bin/bash -i</code>). Once it is allocated, ssh to each node in two terminals as <code>ssh &lt;node name&gt;</code>) and submit the job by typing <code>python train.py --ip_adress=**.**.**.** --nodes 2 --local_rank 0 --ngpus 1 --epochs 1</code> and <code>python train.py --ip_adress=&lt;same as the first&gt; --nodes 2 --local_rank 1 --ngpus 1 --epochs 1</code> to each of them respectively. Two job should start with synchronisation and training will begin soon after.</p> <ul> <li>The ip-address of a node can be obtained by <code>ping &lt;node name&gt;</code></li> </ul>"},{"location":"Technical-Notes/Distributed_dataparallel_pytorch/#distributeddataparallel-as-a-batch-job-in-the-servers","title":"DistributedDataParallel as a Batch job in the servers","text":"<p>When we are submitting the interactive jobs, we know the exact node name and can obtain the ip-address for that beforehand. However, in the batch job, it needs to be programmed to automate most of the stuff. We have to make minimum changes to the existing code and write a <code>.sh</code> script to submit the job. Our <code>train.py</code> script are modified only in the first few lines of the <code>train()</code> function as follows</p> <pre><code>def train(gpu, args):\n\n    args.gpu = gpu\n    print('gpu:',gpu)\n\n    # rank calculation for each process per gpu so that they can be\n    # identified uniquely.\n    rank = int(os.environ.get(\"SLURM_NODEID\")) * args.ngpus + gpu\n    print('rank:',rank)\n    # Boilerplate code to initialise the parallel process.\n    # It looks for ip-address and port which we have set as environ variable.\n    # If you don't want to set it in the main then you can pass it by replacing\n    # the init_method as ='tcp://&lt;ip-address&gt;:&lt;port&gt;' after the backend.\n    # More useful information can be found in\n    # https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html\n\n    dist.init_process_group(\n        backend='nccl',\n        init_method='env://',\n        world_size=args.world_size,\n        rank=rank\n    )\n    torch.manual_seed(0)\n    # start from the same randomness in different nodes.\n    # If you don't set it then networks can have differnt weights in different\n    # nodes when the training starts. We want exact copy of same network in\n    # all the nodes. Then it will progress form there.\n\n    # set the gpu for each processes\n    torch.cuda.set_device(args.gpu)\n</code></pre> <ul> <li>Instead of using local rank in calculation of process rank, we use environment variable <code>$SLURM_NODEID</code> which is unique for each slurm node.</li> </ul> <p>Keeping everything else in the code same, now lets write the batch script for CSC-puhti. Same script can be used for Narvi.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=name\n#SBATCH --account=Project_******\n#SBATCH -o out.txt\n#SBATCH -e err.txt\n#SBATCH --partition=gpu\n#SBATCH --time=08:00:00\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem-per-cpu=8000\n#SBATCH --gres=gpu:v100:4\n#SBATCH  --nodes=2\nmodule load gcc/8.3.0 cuda/10.1.168\nsource &lt;virtual environment name&gt;\n\n# if some error happens in the initialation of parallel process then you can\n# get the debug info. This can easily increase the size of out.txt.\nexport NCCL_DEBUG=INFO  # comment it if you are not debugging distributed parallel setup\n\nexport NCCL_DEBUG_SUBSYS=ALL # comment it if you are not debugging distributed parallel setup\n\n# find the ip-address of one of the node. Treat it as master\nip1=`hostname -I | awk '{print $2}'`\necho $ip1\n\n# Store the master node\u2019s IP address in the MASTER_ADDR environment variable.\nexport MASTER_ADDR=$(hostname)\n\necho \"r$SLURM_NODEID master: $MASTER_ADDR\"\n\necho \"r$SLURM_NODEID Launching python script\"\n\nsrun python train.py --nodes=2 --ngpus 4 --ip_adress $ip1 --epochs 1\n</code></pre> <p>To Narvi users</p> <p>Change the ip1=<code>hostname -I | awk '{print $2}'</code> line to ip1=<code>hostname -I | awk '{print $1}'</code> to correctly parse the ip address.</p> <p>To Mahti users</p> <p>For now add <code>export NCCL_IB_DISABLE=1</code> to the batch script to prevent the occasional hang in the training loop. However, I am not sure whether this is happening becasue of Mahti or Pytorch 1.8.</p>"},{"location":"Technical-Notes/Distributed_dataparallel_pytorch/#tips-and-tricks","title":"Tips and Tricks","text":"<ul> <li>If you have <code>os.mkdir</code> inside the script then always wrap it with <code>try and except</code>. Multiple processes will try to create a new folder and they will throw errors that the directory already exists.</li> <li>When resuming the network weights if your model complains that the tensors are not on the same advice and points to the optimiser then it is mostly caused by this optimizer-error. Just add these few lines after loading the optimizer from the checkpoints.</li> </ul> <pre><code>for state in optimizer.state.values():\n    for k, v in state.items():\n        if isinstance(v, torch.Tensor):\n            state[k] = v.cuda(gpus)\n</code></pre> <ul> <li>To run on a single node with multiple gpus, just make the <code>--nodes=1</code> in the batch script.</li> <li>If you Batchnorm*d inside the network then you may consider replacing them with <code>sync-batchnorm</code> to have better batch statistics while using DistributedDataParallel.</li> <li>Use this feature when it is required to optimise the gpu usage.</li> </ul>"},{"location":"Technical-Notes/Distributed_dataparallel_pytorch/#acknowledgements","title":"Acknowledgements","text":"<p>I found this article really helpful when I was setting up my DistributedDataParallel framework. Many missing details can be found in this article which is skipped here to focus more on the practical things. If you have any suggestions then reach me at <code>soumya.tripathy@tuni.fi</code>.</p>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/","title":"An automation script to run your job to Puhti or Mahti","text":""},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Motivation</li> <li>Dislaimer</li> <li>Introduction<ol> <li>What is the automation script?</li> <li>Why use the automation script?</li> <li>How does the automation script work?</li> <li>What are the requirements for using the automation script?</li> <li>What are the limitations of the automation script?</li> </ol> </li> <li>How to use it<ol> <li>How to start a new job</li> <li>How to check the status of a job</li> <li>How to stop a running job</li> </ol> </li> <li>How to use this script for PyTorch model training<ol> <li>How to modify the PyTorch-based model training script</li> <li>Some notifications for the command you want to run</li> <li>Distributed Data Parallel (DDP) with PyTorch</li> </ol> </li> <li>Some errors and solutions</li> <li>Contact</li> </ol>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#motivation","title":"Motivation","text":"<p>If you want to train some huge models, you might want to use the supercomputers like Puhti or Mahti. However, due to the limitations from SLURM clusters, the process of submitting a job to the supercomputers is not straightforward. You need to write a SLURM script, submit the job, and check the status of the job. This process is time-consuming and needs you to submit the job manually, which will lead to lots of time wasted if you couldn't apply for new resources after the current work is done. Therefore, we provide an automation script to help you submit your job to Puhti or Mahti. You don't need to worry that your job stops running during the night or your holiday anymore. Just enjoy your time and let the automation script do the rest for you.</p>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#disclaimer","title":"Disclaimer","text":"<ul> <li>Important! Please follow the rules of CSC when using this script! If you have any questions about the rules, please check the   information on Docs CSC.</li> <li>This script is binary encrypted, and the source code is not available. Please use it following the instructions and do   not modify it.</li> <li>This script is only available for Puhti or Mahti.</li> <li>This script is only available for non-interactive jobs. If you want to run an interactive job, you need to submit the   job manually.</li> <li>This script is only available for 4 jobs at the same time. If you want to run more jobs, you need to stop some of them   first.</li> <li>If you got any problems or bugs when using this script, please contact me.</li> </ul>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#introduction","title":"Introduction","text":""},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#what-is-the-automation-script","title":"What is the automation script?","text":"<p>This is a encrypted shell script that can help you submit your job to Puhti or Mahti.</p>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#why-use-the-automation-script","title":"Why use the automation script?","text":"<p>It will automatically apply for some resources and submit your job to the supercomputers. After the current job gets close to the time limit, the script will automatically apply for new resources and submit the job again. What's more, the old resources will be released immediately when the new resources are allocated. You don't need to worry that your job stops running due to the time limit of the server anymore.</p>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#how-does-the-automation-script-work","title":"How does the automation script work?","text":"<p>This automation script will run as the 5 steps below:</p> <ul> <li>Step 1: Apply for the required resources on SLURM clusters</li> <li>Step 2: Start to timing as soon as getting the resources</li> <li>Step 3: Submit a new request for resources when the remaining time is 1/3 of the whole requested time</li> <li>Step 4: Stop the current job and release the resources as soon as the new resources are allocated</li> <li>Step 5: Repeat the steps above</li> </ul>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#what-are-the-requirements-for-using-the-automation-script","title":"What are the requirements for using the automation script?","text":"<ul> <li>You need to have a user account available on Puhti or Mahti</li> <li>You need to put this automation script into your user directory on Puhti or Mahti</li> <li>If this script couldn't be executed, you need to give the execution permission to it by   running <code>chmod +x auto_gpu</code></li> </ul>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#what-are-the-limitations-of-the-automation-script","title":"What are the limitations of the automation script?","text":"<ul> <li>This script is only available on Puhti or Mahti</li> <li>This script limits the maximum of jobs you can run at the same time to 4 in order to avoid the congestion and the   waste of resources</li> <li>This script is not available for psuedo-interactive jobs, which will lead to lots of resources wasted. If you want to   run a psuedo-interactive job, you need to submit the job manually</li> <li>If you want to train a model with PyTorch for a long while, which would be split into several jobs due to the time   limit of the server, you need to modify the PyTorch-based model training script. (details   in How to modify the PyTorch-based model training script)</li> <li>This script can not stop automatically. You need to stop it manually when you want to stop the automation script. (   details in How to stop a running job)   And please remember to stop the script after your work is done to avoid the waste of resources.</li> </ul>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#how-to-use-it","title":"How to use it","text":"<p>Please firstly download the script from the following link: auto_gpu. Then you can put it into your user folder. And you can run the script by the following command:</p> <pre><code>./auto_gpu\n</code></pre> <p>If the permission is denied, you can give the execution permission to it by running the following command:</p> <pre><code>chmod +x auto_gpu\n</code></pre> <p>Then it can work properly.</p>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#how-to-start-a-new-job","title":"How to start a new job","text":"<p>This script provides a lot of options for you to customize your job. If you want to check the help information, you can choose one of the following commands:</p> <pre><code>./auto_gpu -h\n./auto_gpu --help\n</code></pre> <p>And the information will be shown as below:</p> <pre><code>Options:\n  -h, --help                            Display help.\n\n  -j &lt;job_name&gt;, --job_name=&lt;job_name&gt;  Set the job name you want to use. No default value. Please set different names for different jobs! This is an identifier for the job.\n\n  -a &lt;account&gt;, --account=&lt;account&gt;     Set the account you want to use. No default value.\n\n  -t &lt;time&gt;, --want_time=&lt;time&gt;         Set the time you want to use the GPU (!!!the maximum of one round, not the whole time!!!), and the format must be 'D-HH:MM:SS' (D: days, HH: hours, MM: minutes, SS: seconds). The default is 0-00:15:00.\n\n  -s, --small                           Use gpusmall on mahti.\n  -m, --medium                          Use gpumedium on mahti.\n  -l, --large                           Use gpu on puhti.\n\n  -n &lt;num&gt;, --num_nodes=&lt;num&gt;           Set the number of nodes you want to use. The default is 1.\n\n  -g &lt;num&gt;, --num_gpus_per_node=&lt;num&gt;   Set the number of GPUs per node you want to use. The default is 1.\n\n  --nvme=&lt;num&gt;, --nvme_per_node=&lt;num&gt;   Set the local storage per node (GB) you want to use. No default value.\n\n  --num_tasks_per_node=&lt;num&gt;            Set the number of tasks per node you want to use. The default is 1.\n\n  -c &lt;num&gt;, --num_cpus_per_task=&lt;num&gt;   Set the number of CPUs per task you want to use. The default is 4.\n\n  --mem_per_cpu=&lt;num&gt;                   Set the memory per CPU you want to use. The default is 8000.\n\n  --cmd=&lt;command&gt;, --command=&lt;command&gt;  Set the command you want to run, it must be double quote. No default value.\n</code></pre> <p>Now, if we want to apply for 1 node with 1 GPU (gpusmall) on Mahti for 1 hour to run , we can run one of the following commands: <pre><code>./auto_gpu -t 0-01:00:00 -s -j &lt;your_job_name&gt; -a &lt;your_csc_group_name&gt; --cmd=\"&lt;your_command&gt;\"\n./auto_gpu --want_time=0-01:00:00 --small --job_name=&lt;your_job_name&gt; --account=&lt;your_csc_group_name&gt; --command=\"&lt;your_command&gt;\"\n</code></pre> <p>If you want to apply for different GPU type, more time, nodes, GPUs, CPUs, or memory, you can customize the options as you want.</p>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#how-to-check-the-status-of-a-job","title":"How to check the status of a job","text":"<p>This script will automatically output the job ID and the node name immediately after getting the resources. You can check it directly from the terminal. If you want to check the status of the job (like partition, name, state, time, etc.), you can run the following command:</p> <pre><code>squeue -u &lt;your_username&gt;\n</code></pre>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#how-to-stop-a-running-job","title":"How to stop a running job","text":"<p>If you want to stop a running job, You can do the following steps:</p> <ul> <li>Step 1. Press <code>Ctrl + C</code> to stop the script</li> <li>Step 2. Run the following command to check which job you want to stop, and copy the job ID</li> </ul> <pre><code>squeue -u &lt;your_username&gt;\n</code></pre> <ul> <li>Step 3. Run the following command to stop the job</li> </ul> <pre><code>scancel &lt;job_id&gt;\n</code></pre>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#how-to-use-this-script-for-pytorch-model-training","title":"How to use this script for PyTorch model training","text":""},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#how-to-modify-the-pytorch-based-model-training-script","title":"How to modify the PyTorch-based model training script","text":"<p>If you want to train a model with PyTorch for a long while, which might be split into several rounds due to the time limit of the server. In this case, the model will be refreshed every time you submit a new job. Therefore, you need to save the parameters of the model every epoch, and load the latest parameters when you start a new job. Here is an example of how to modify the PyTorch-based model training script:</p> <pre><code># save the model after each epoch\nimport os\n\ntorch.save(model.state_dict(), '/&lt;your_model_path&gt;/&lt;your_model_name&gt;_{:d}.pth'.format(epoch_idx))\n\n# remove the old model automatically (If you want to check some old models, you can remove this line)\n# But please remember to clean the old models in time to avoid the waste of resources\nos.remove('/&lt;your_model_path&gt;/&lt;your_model_name&gt;_{:d}.pth'.format(epoch_idx - 1))\n\n# load the latest model\nepoch_list = [int(model_name.split('_')[-1].split('.')[0]) for model_name in os.listdir('/&lt;your_model_path&gt;/') if\n              model_name.endswith('.pth')]\nmax_epoch = max(epoch_list)\nmodel.load_state_dict(\n    torch.load('/&lt;your_model_path&gt;/&lt;your_model_name&gt;_{:d}.pth'.format(max_epoch), map_location=\"&lt;your_device&gt;\"))\n</code></pre> <p>Note:</p> <ul> <li>You need to replace <code>&lt;your_model_path&gt;</code>, <code>&lt;your_model_name&gt;</code>, and <code>&lt;your_device&gt;</code> with your own information.</li> <li>You need to use similar methods to save any other information required to continue the training, like the optimizer,   the scheduler, activation function, etc.</li> <li>Please remove the saved model in time, coz they will take up a lot of space. Or you can write a script to remove the   old models automatically.</li> <li>Please remember to stop the script after your work is done to avoid the waste of resources.</li> </ul>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#some-notifications-for-the-command-you-want-to-run","title":"Some notifications for the command you want to run","text":"<ul> <li>Because directly running this script may only get your default Python environment, it's better to use the absolute   path   of your python interpreter and the script you want to run.</li> <li>Please also use the absolute path of the Python script you want to run.</li> <li>If you want to save the training logs, you can redirect the output to a file.</li> </ul> <p>Here is an example:</p> <pre><code>./auto_gpu -t 0-01:00:00 -s -j &lt;your_job_name&gt; -a &lt;your_csc_group_name&gt; --cmd=\"/&lt;your_anaconda_path&gt;/anaconda3/envs/&lt;your_env_name&gt;/bin/python /&lt;your_python_project_path&gt;/&lt;your_python_script_name&gt;.py &gt;&gt; /&lt;your_log_path&gt;/&lt;your_log_name&gt;.log\"\n</code></pre>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#distributed-data-parallel-ddp-with-pytorch","title":"Distributed Data Parallel (DDP) with PyTorch","text":"<p>This script is also available for Distributed Data Parallel (DDP) with PyTorch. You can apply for multiple nodes and multiple GPUs on each node to train your model. There is already an excellent tutorial on how to use DDP on Puhti or Mahti. Please find the tutorial here. Thanks to Soumya ( soumya.tripathy@tuni.fi).</p>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#some-errors-and-solutions","title":"Some errors and solutions","text":"<ul> <li>Wrong server</li> </ul> <pre><code>Please run this script on Puhti or Mahti.\n</code></pre> <ul> <li>Invalid input, terminating...</li> </ul> <pre><code>Please check the input parameters and try again.\n</code></pre> <ul> <li>The account is empty.</li> </ul> <pre><code>Please set the account you want to use.\n</code></pre> <ul> <li>The command you want to run is empty.</li> </ul> <pre><code>Please set the command you want to run with double quotes.\n</code></pre> <ul> <li>The job name is empty.</li> </ul> <pre><code>Please set the job name you want to use.\n</code></pre> <ul> <li>mahti does not support the gpu_type 'gpu'.</li> </ul> <pre><code>Please choose the correct GPU type (small -s or medium -m) for Mahti.\n</code></pre> <ul> <li>puhti does not support the gpu_type 'gpusmall' / 'gpumedium'.</li> </ul> <pre><code>Please choose the correct GPU type (gpu -l) for Puhti.\n</code></pre> <ul> <li>Due to the resources limitation, please do not automatically apply for an interactive job, which will lead to lots of   waste of resources. Please apply for such jobs manually.</li> </ul> <pre><code>Please run some non-interactive jobs.\n</code></pre> <ul> <li>The format of time should be 'D-HH:MM:SS' (D: days, HH: hours, MM: minutes, SS: seconds)</li> </ul> <pre><code>Please set the time with the correct format.\n</code></pre> <ul> <li>You have already applied for the job , please use another job name. <pre><code>Please set a different job name for different jobs.\n</code></pre> <ul> <li>You have already applied for too many jobs, please stop some of them first.</li> </ul> <pre><code>Please stop some of the running jobs.\n</code></pre> <ul> <li>Something wrong happened; please check if your request meets the rules of the server.</li> </ul> <pre><code>Please check the info on (https://docs.csc.fi/computing/running/batch-job-partitions/)\n</code></pre>"},{"location":"Technical-Notes/automatically-submit-your-job-to-puhti-or-mahti/#contact","title":"Contact","text":"<p>If you have any questions or suggestions, please feel free to contact me, Shiqi Zhang (shiqi.zhang@tuni.fi).</p>"},{"location":"Technical-Notes/custom_LUMI_python_envs/","title":"Setting up Python environments on LUMI: Or why you shouldn't use the LUMI container wrapper","text":"<p>This guide provides instructions on how to create custom Python environments on the EuroHPC LUMI supercomputer in a way that ensures inter-node communication works properly. This is essential for running multi-node machine learning jobs on LUMI using e.g. PyTorch, TensorFlow, and JAX.</p> <p>All the information provided here is also available in LUMI official documentation, but as the information is scattered across multiple pages, it can be difficult to find the relevant details. This guide aims to consolidate that information and provide a clear, step-by-step process for setting up your custom environment.</p> <p>All the scripts used in this guide are available in this GitHub repository, so that it can be easily tested on LUMI.</p>"},{"location":"Technical-Notes/custom_LUMI_python_envs/#table-of-contents","title":"\ud83d\udcd6 Table of Contents","text":"<ol> <li>Motivation</li> <li>Building a Python environment with Cotainr</li> <li>Running jobs with the environment</li> <li>Contact</li> </ol>"},{"location":"Technical-Notes/custom_LUMI_python_envs/#motivation","title":"\ud83e\udd14 Motivation","text":"<p>Many users move to LUMI from CSC clusters like Mahti and Puhti, where it is convenient to create custom Python environments using the Tykky tool for wrapping Conda environments in Singularity containers. </p> <p>A similar tool, LUMI container wrapper, is also available on LUMI and is tempting to use because of the familiar workflow. However, using the container wrapper on LUMI has significant drawbacks, especially for multi-node training jobs. Let's consider an example of training a PyTorch model using Distributed Data Parallel (DDP) across two nodes. Here are the epoch durations with environments created in two different ways:</p> <p><pre><code># With an environment created with LUMI container wrapper\nEpoch 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2442/2442 [06:20&lt;00:00,  6.42it/s]\n\n# With an environment created following this guide\nEpoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2442/2442 [00:49&lt;00:00, 49.25it/s]\n</code></pre> As you can see, the run with the LUMI container wrapper environment is ~7x slower! But why?</p> <p>The reason is that fast node-to-node communication on LUMI requires the AWS OFI plugin for RCCL, which is the AMD GPU collective communication library, replacement for NVIDIA NCCL. The plugin enables RCCL to use LUMI's Slingshot-11 interconnect, as RCCL does not support it out of the box. LUMI container wrapper installs start from a minimal base image that does not include the AWS OFI plugin. While it is possible to manually inject the plugin, it is easier to build Python environments on top of pre-configured ROCm images that already include it. This can be achieved using the Cotainr tool available on LUMI.</p>"},{"location":"Technical-Notes/custom_LUMI_python_envs/#building-a-python-environment-with-cotainr","title":"\ud83d\udd28 Building a Python environment with Cotainr","text":"<p>To build the example environment on LUMI, clone the example repository and run the <code>create_environment.sh</code> script:</p> <pre><code>cd /scratch/&lt;your_LUMI_project_id&gt;\ngit clone https://github.com/lasuomela/LUMI-Project-Template.git\ncd LUMI-Project-Template\n\nsbatch -A &lt;your_LUMI_project_id&gt; slurm_tools/create_environment.sh\n</code></pre> <p>The script creates a new Singularity image with the Conda and pip packages specified in <code>environment.yml</code> on top of an ROCm base image provided by LUMI.</p> <p>Additionally, it creates a SquashFS file that contains a Python virtual environment (venv) with the pip packages that cannot be installed directly with Conda. An editable install of a package you are developing is a good example of such a package. The SquashFS file is mounted inside the Singularity image at runtime to make the packages available.</p> <p>The environment build is done on a compute node to ensure sufficient RAM and CPU. The build process takes some time, you can monitor the progress in the <code>log_build.out</code> and <code>log_build.err</code> files generated by SLURM.</p> <p>Here you can see the content of <code>create_environment.sh</code> for reference:</p> <pre><code>#!/bin/bash -l\n#SBATCH --job-name=lumi_env_build     # Job name\n#SBATCH --output=logs/log_build.out      # Name of stdout output file\n#SBATCH --error=logs/log_build.err       # Name of stderr error file\n#SBATCH --partition=small               # partition name\n#SBATCH --nodes=1                       # Total number of nodes \n#SBATCH --ntasks-per-node=1             # MPI ranks per node\n#SBATCH --cpus-per-task=64\n#SBATCH --mem=256G                      # Total memory for job\n#SBATCH --time=0-00:20:00               # Run time (d-hh:mm:ss)\n\n# Reference:\n# https://github.com/Lumi-supercomputer/Getting_Started_with_AI_workshop/blob/main/07_Extending_containers_with_virtual_environments_for_faster_testing/examples/extending_containers_with_venv.md\n\n# Name of the image to create\nIMAGE_NAME=pytorch_example.sif\n\n# Path to the package being developed\nPKG_DIR=/scratch/$SLURM_JOB_ACCOUNT/LUMI-Project-Template\n\n# Where to store the image\nINSTALL_DIR=/projappl/$SLURM_JOB_ACCOUNT/pytorch_example\n\n# Path to your conda environment file\nENV_FILE_PATH=$PKG_DIR/environment.yml\n\n# Path to the environment base image. Choose a ROCm version that matches your needs.\n# On the base images, RCCL is properly configured to use the high-speed Slingshot-11 interconnect\n# between nodes. This ensures optimal performance when training across multiple nodes.\nBASE_IMAGE_PATH=/appl/local/containers/sif-images/lumi-rocm-rocm-6.2.4.sif\n\n# Remove the old environment\nif [ -d \"$INSTALL_DIR\" ]; then\n    rm -rf $INSTALL_DIR\nfi\nmkdir -p $INSTALL_DIR\n\n# Purge modules and load cotainr module\nmodule purge\nmodule load LUMI/24.03 cotainr\n\n# Install the conda/pip dependencies specified in the .yml file\nsrun cotainr build $INSTALL_DIR/$IMAGE_NAME \\\n    --base-image=$BASE_IMAGE_PATH \\\n    --conda-env=$ENV_FILE_PATH \\\n    --accept-license\n\n# Stuff beyond here is optional but useful\n\n# Load modules needed for running Singularity containers\nmodule use  /appl/local/containers/ai-modules\nmodule load singularity-AI-bindings\n\n# Create a virtual environment to install stuff that cannot be installed via conda\n# such as an editable install of the package being developed\n# or packages you want to install with the --no-deps flag\nsingularity exec $INSTALL_DIR/$IMAGE_NAME bash -c \"\n  python -m venv $INSTALL_DIR/myenv --system-site-packages &amp;&amp;\n  source $INSTALL_DIR/myenv/bin/activate &amp;&amp;\n  pip install git+https://github.com/bdaiinstitute/theia.git --no-deps &amp;&amp;\n  pip install -e $PKG_DIR &amp;&amp;\n  deactivate\n\"\n\n# Create a SquashFS image of the virtual environment\nmksquashfs $INSTALL_DIR/myenv $INSTALL_DIR/myenv.sqsh\nrm -rf $INSTALL_DIR/myenv\n</code></pre> <p>and the <code>environment.yml</code>:</p> <pre><code># An example PyTorch environment for LUMI\nname: pytorch_example\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - python=3.10\n  - pip\n  - lightning&gt;=2.5.1\n  - pip:\n    # The PyTorch ROCm version here should match the ROCm version\n    # of the base image you chose in create_environment.sh\n    - --extra-index-url https://download.pytorch.org/whl/rocm6.2.4\n    - torch==2.6.0+rocm6.2.4\n    - torchvision==0.21.0+rocm6.2.4\n</code></pre>"},{"location":"Technical-Notes/custom_LUMI_python_envs/#running-jobs-with-the-environment","title":"\ud83d\ude80 Running jobs with the environment","text":"<p>Once the environment is built, you can run the example PyTorch job like <pre><code>sbatch -A &lt;your_LUMI_project_id&gt; slurm_tools/run.sh\n</code></pre></p> <p>You can change the number of GPUs and nodes in the <code>run.sh</code> script. If everything is set up correctly, you should see fast epoch times similar to the ones shown in the Motivation section, and the epoch times should decrease ~linearly as you increase the number of nodes used for training.</p> <p>Here is the content of <code>run.sh</code> for reference: <pre><code>#!/bin/bash -l\n#SBATCH --job-name=pytorch_example     # Job name\n#SBATCH --output=logs/log_test.out      # Name of stdout output file\n#SBATCH --error=logs/log_test.err       # Name of stderr error file\n#SBATCH --partition=dev-g               # partition name\n#SBATCH --nodes=2                       # Total number of nodes \n#SBATCH --ntasks-per-node=1             # MPI ranks per node\n#SBATCH --gpus-per-node=1               # Allocate one gpu per MPI rank\n#SBATCH --cpus-per-task=7               # CPU cores per task\n#SBATCH --mem=480G                      # Total memory for job\n#SBATCH --time=0-02:00:00               # Run time (d-hh:mm:ss)\n\n# Reference:\n# https://github.com/Lumi-supercomputer/Getting_Started_with_AI_workshop/blob/main/07_Extending_containers_with_virtual_environments_for_faster_testing/examples/extending_containers_with_venv.md\n\n# Path to the environment. Same as INSTALL_DIR in create_environment.sh\nENV_DIR=/projappl/$SLURM_JOB_ACCOUNT/pytorch_example\n\n# Name of the image to to use\nIMAGE_NAME=pytorch_example.sif\n\n# Load the required modules\nmodule purge\nmodule load LUMI\nmodule use  /appl/local/containers/ai-modules\nmodule load singularity-AI-bindings\n\nsource ~/.bashrc\nexport SINGULARITYENV_PREPEND_PATH=/user-software/bin # gives access to packages inside the container\n\n# Tell RCCL to use only Slingshot interfaces and GPU RDMA\nexport NCCL_SOCKET_IFNAME=hsn0,hsn1,hsn2,hsn3\nexport NCCL_NET_GDR_LEVEL=PHB\n\n# Run the training script:\n# We use the Singularity container from 'create_environment.sh'\n# with the --bind option to mount the virtual environment in $ENV_DIR/myenv.sqsh\n# into the container at /user-software.\n#\n# The number of GPUs and nodes are auto-detected from the SLURM environment variables.\nsrun singularity exec \\\n   -B $ENV_DIR/myenv.sqsh:/user-software:image-src=/ $ENV_DIR/$IMAGE_NAME \\\n    python -m pytorch_example.run \\\n        --num_gpus=$SLURM_GPUS_ON_NODE \\\n        --num_nodes=$SLURM_JOB_NUM_NODES \\\n\n# Bonus:\n# With full-node allocations, i.e. running jobs on standard-g or small-g with slurm argument `--exclusive,\n# it is beneficial to set the CPU bindings (see https://docs.lumi-supercomputer.eu/runjobs/scheduled-jobs/distribution-binding/#gpu-binding)\n\n# # Define CPU binding for optimal performance in full-node allocations\n# CPU_BIND=\"mask_cpu:fe000000000000,fe00000000000000\"\n# CPU_BIND=\"${CPU_BIND},fe0000,fe000000\"\n# CPU_BIND=\"${CPU_BIND},fe,fe00\"\n# CPU_BIND=\"${CPU_BIND},fe00000000,fe0000000000\"\n\n# srun --cpu-bind=$CPU_BIND singularity exec \\\n#    -B $ENV_DIR/myenv.sqsh:/user-software:image-src=/ $ENV_DIR/$IMAGE_NAME \\\n#     python -m pytorch_example.run \\\n#         --num_gpus=$SLURM_GPUS_ON_NODE \\\n#         --num_nodes=$SLURM_JOB_NUM_NODES \\\n</code></pre></p>"},{"location":"Technical-Notes/custom_LUMI_python_envs/#contact","title":"Contact","text":"<p>That's it! If you have any questions or run into issues, feel free to reach out to <code>lauri.a.suomela@tuni.fi</code> or open an issue in the GitHub repository.</p>"},{"location":"Technical-Notes/how-to-set-up-remote-access/","title":"How to Set up Remote Access","text":"<p>This is the guide for setting up the remote connection to your office machine and it will not tell you how to set up the machine itself (e.g. install Ubuntu, allocate disk space). If you would like some guidance on this topic, for example, you would want to make your remote machine to \"look\" like the rest of our machines, please refer to this unofficial guide \u2013 also, let us know if it was useful and whether the wiki might benefit from having it here.</p> <p>Warning</p> <p>Since this guide relies on <code>ssh-forward.tuni.fi</code> as a proxy server, you may only set up the remote connection if you are a staff member of the university, i.e. a student cannot apply for access to <code>ssh-forward.tuni.fi</code>. If you are a student, please contact the IT-Helpdesk and ask if they can give you access to <code>ssh-forward.tuni.fi</code>.</p> <p>A bit of motivation and how it will work. There is no official way of conneting remotely to a self-maintained machine. Here is how we can work around this problem. Your compute machine can be added to a research network <code>pit.cs.tut.fi</code> which practically means that it will have a fixed IP (or FQDN) and you will not need to type your credentials every 24 hours. However, another problem here is that this research network can only be reachable using university-maintained devices which uses a university WiFi or a pre-installed VPN. The solution to this problem is to use a proxy ssh-server (<code>ssh-forward.tuni.fi</code>) when connecting to your machine. This ssh-forwarding server is open to the public internet and from there you can reach <code>pit.cs.tut.fi</code>.</p> <p>We assume that you have an Linux desktop (host) at your office and you would like to access it remotely from any device, e.g. your laptop (client). Here we provide both: how to setup the host and the client sides. If the host is already set up and you would like to just learn how to connect to it, follow the guide for a client.</p>"},{"location":"Technical-Notes/how-to-set-up-remote-access/#how-to-set-up-the-host-eg-compute-machine","title":"How to Set up the Host (e.g. compute machine)?","text":"<ol> <li>Email <code>it-helpdesk@tuni.fi</code> and ask them to connect your office machine to <code>pit.cs.tut.fi</code> network. They will assign a fixed IP/FQDN and you will not need to type your credentials every 24 hours to have an internet connection. Specify the following information:<ul> <li>the inventory number of the machine (on the sticker),</li> <li>MAC address of the socket in the machine you would like to use for the wired connection to the internet (you may have several Ethernet ports \u2013 you need only one),</li> <li>mention the Ethernet socket number from the wall that you will use.</li> </ul> </li> <li>At this point, you should have had received the response from <code>it-helpdesk@tuni.fi</code> and be able to connect to the internet using the socket you specified. If so, check your IP and type <code>host your_IP</code> in your terminal to find out the FQDN of the machine. In our case, it was be something like <code>&lt;IP.reversed&gt; pointed to **********.pit.cs.tut.fi</code>.</li> <li>Install <code>openssh-server</code> package on your host machine (via e.g. <code>sudo apt-get install openssh-server</code>). This will allow <code>ssh</code> connection to this machine.</li> <li>Next, make sure no WiFi connection connects automatically after the startup. On Ubuntu, type <code>sudo nm-connection-editor</code> in your terminal (or just go to <code>Edit connection</code> from the status menu on Ubuntu 16.04).</li> <li>Also, allow your connection (by default called <code>Wired connection</code>) to automatically connect when available.</li> </ol> <p>Now your machine (host) should be reachable from TUNI-maintained computers connected to <code>TUNI-STAFF</code> WiFi or a pre-installed VPN directly via <code>ssh user@**********.pit.cs.tut.fi</code>. If you are using a non-university computer, you need to use the ssh-forwarding server (<code>ssh-forward.tuni.fi</code>) to reach <code>pit.cs.tut.fi</code>. Use the following guide to set up the connection to the forwarding server.</p>"},{"location":"Technical-Notes/how-to-set-up-remote-access/#how-to-set-up-the-client-eg-your-laptop","title":"How to Set up the Client (e.g. your laptop)?","text":"<p>Even though university-maintained devices can reach <code>pit.cs.tut.fi</code> without any proxy from university premises, we found that using the proxy even on university-maintained devices provides a more uniform experience. Otherwise you need to keep in mind which network you are using each time you ssh to your machine and adjust the CLI command accordingly (see the tip in the end of this section on how to configure an <code>ssh</code> command to use proxy by default when connecting to a specific device).</p> <ol> <li>To connect to your compute machine from a self-maintained/personal device, you need to get access to the ssh-forwarding server <code>ssh-forward.tuni.fi</code>. For this, proceed to id.tuni.fi/idm -&gt; <code>My user rights</code> -&gt; <code>Apply for a new user right</code> -&gt; if required, select your Staff contract -&gt; search for <code>Linux Servers (LINUX-SERVERS) Personnel SSH tunneling service</code> and select it. In <code>Application details</code> put something like <code>For pit.cs.tut.fi connections</code>. Then, go to the <code>Applications</code> tab and wait until the access is granted (1 min).</li> <li><code>ssh-forward.tuni.fi</code> is open to the public internet and it requires 2-factor authentication. For this, log in to the forwarding server using your TUNI credentials (<code>ssh tuni_user@ssh-forward.tuni.fi</code>) while being connected to one of the University networks (<code>roam.fi/eduroam/TUNI-STAFF</code> or a university VPN). If 2FA was not initialized, it will reject your password. Unfortunately, you cannot initialize 2-factor authentication from any network. You need to be physically at University and be connected to one of the networks there.</li> <li>Once you logged in to <code>ssh-forward.tuni.fi</code>, type <code>google-authenticator</code>. It will ask you several questions and show a QR code (resize your window to see it). Answer the questions as follows:<ul> <li><code>Do you want authentication tokens to be time-based...</code> -&gt; y</li> <li><code>Do you want me to update your \"/home/user/...google_authenticator\" file</code> -&gt; y</li> <li><code>Do you want to disallow multiple uses...</code> -&gt; n</li> <li><code>By default, tokens are good for 30 seconds...</code> -&gt; n</li> <li><code>If the computer that you are logging into...</code> -&gt; y</li> </ul> </li> <li>Once QR code is shown, install some 2-factor authenticator app on your smartphone if you don't have one yet e.g. from Microsoft, Authy, or Google. The app will be used for two-step authentication when you connect from a non-university network is used e.g. your home internet. Once it is done, it will create an entry with a 6-digit passcode which changes every 30 secs.</li> <li>Test your 2FA by trying to connect to <code>ssh-forward.tuni.fi</code> from a non-university network (e.g. using internet shared from your cell-phone) (<code>ssh your_tuni_username@ssh-forward.tuni.fi</code>).</li> <li>Now you can connect to your machine from your local terminal jumping through the ssh proxy. Here is a convenient command: <code>ssh -J your_tuni_username@ssh-forward.tuni.fi your_host_username@*********.pit.cs.tut.fi</code> (<code>-J</code> means \"jump\" using the specified proxy)<ul> <li>If you are on a University network (<code>roam.fi/eduroam/TUNI-STAFF</code> or VPN), it will only ask for your TUNI and host passwords;</li> <li>If you are using a non-University network, it will first ask you for a <code>Verification code</code> which is a temporal code from the 2FA app you installed on your smartphone. Then, you will need to type your TUNI and host passwords.</li> </ul> </li> </ol> <p>Tip</p> <p>Config the <code>ssh</code> connection in <code>~/.ssh/config</code>: <pre><code>Host connection_name\n  HostName ***********.pit.cs.tut.fi\n  User your_host_username\n  ProxyCommand ssh your-tuni-username@ssh-forward.tuni.fi -W %h:%p\n</code></pre> After doing this, you will be able to do <code>ssh connection_name</code> to <code>ssh</code> directly to <code>*********.pit.cs.tut.fi</code>, forward ports, and transfer large files using <code>scp/rsync</code>. It is also useful if you are using <code>VSCode</code> or any other text editor which supports remote development. Additionally, it is handy if you would like to mount folders from the host to your client. You can use <code>sshfs connection_name:/path/to/remote_folder /path/to/local_folder</code>.</p>"},{"location":"Technical-Notes/how-to-set-up-remote-access/#optional-how-to-set-up-ssh-keys","title":"(Optional) How to Set up SSH Keys","text":"<p>To avoid needing to constantly give your TUNI password to the proxy server and host password when connecting to your SAUNA machine, your SSH key pair should be set up. An SSH key is a cryptographic key used for secure, authenticated access to a remote server. The SSH key pair consists of a private key, stored on your local machine, and a public key which is added to the remote server. Never share your private key. Use the following instructions to set up your SSH keys for your SAUNA machine.</p> <ol> <li>Generate your SSH key-pair on your local machine. Identify with your email <code>ssh-keygen -t ed25519 -C \"your_email@example.com\"</code>. Press the enter key at each of the questions.</li> <li>Add your public key to the forwarding server with command <code>ssh-copy-id your_tuni_username@ssh-forward.tuni.fi</code>. This will require your TUNI password once.</li> <li>Test that it worked (no password should be required for this login) <code>ssh your_tuni_username@ssh-forward.tuni.fi</code>. Return to local machine with <code>exit</code>.</li> <li> <p>Now, we do the same to the SAUNA machine. Follow the steps below depending on if you have set up your <code>~/.ssh/config</code>.</p> <p>a. (RECOMMENDED) Requires the outcome of the above tip regarding your <code>~/.ssh/config</code> file. Add your public key to the SAUNA machine with the command <code>ssh-copy-id &lt;connection_name&gt;</code>, where <code>connection_name</code> was set in the tip above in your <code>~/.ssh/config</code>. You will need to give the host password once.</p> <p>b. (NOT RECOMMENDED) Alternatively, when using the long command above, we need to copy the public key manually. You can find the name of your public key file with <code>ls ~/.ssh/*.pub</code>. However, with the generation command in these instructions it would be <code>id_ed25519.pub</code>. Now, copy your public key to the SAUNA machine with the command: <pre><code>cat ~/.ssh/&lt;name_of_public_key_file&gt;.pub | ssh -J your_tuni_username@ssh-forward.tuni.fi your_host_username@*********.pit.cs.tut.fi 'mkdir -p ~/.ssh &amp;&amp; cat &gt;&gt; ~/.ssh/authorized_keys &amp;&amp; chmod 600 ~/.ssh/authorized_keys'\n</code></pre> It will ask the host passwork once. Then you can test if it worked by running the long command <code>ssh-copy-id -J your_tuni_username@ssh-forward.tuni.fi your_host_username@*********.pit.cs.tut.fi</code>. Now it should not ask for the host password.</p> </li> </ol> <p>If everything went as it should, now connecting to your SAUNA machine should not require any passwords in terminal, VSCode, etc.</p>"},{"location":"Technical-Notes/how-to-set-up-remote-access/#known-issues","title":"Known Issues","text":"<ul> <li>At the moment, only a staff member (doctorate students are staff members usually) can use <code>ssh-forward.tuni.fi</code> proxy and, therefore, benefit from this set up. Please, let us know if you found a way around it.</li> <li>You will need to contact <code>it-helpdesk@tuni.fi</code> and ask to activate and configure your wall internet socket in a special way. This might take some time.</li> <li>Depending on the network you are using, a different log in procedure will be required: only your TUNI password if you are connected to <code>roam.fi/eduroam/TUNI-STAFF</code>; and 2FA + your TUNI and host-machine passwords  on other networks.</li> <li><code>ssh-forward.tuni.fi</code> has very limited disk space for each user (few MB). Therefore, can only be used as a proxy for your <code>ssh</code> connection which is its main purpose.</li> </ul>"},{"location":"Technical-Notes/install-tuni-vpn/","title":"Install TUNI VPN","text":"<p>The TUNI intra documentation is here https://intra.tuni.fi/en/handbook?page=2638 but its kind of a mess and therefore below easy to follow information.</p>"},{"location":"Technical-Notes/install-tuni-vpn/#self-maintained-linux-box-tested-ubuntu-1804","title":"Self-maintained Linux Box (tested Ubuntu 18.04)","text":"<p>eduVPN application is not available for Linux and thefore you must use openvpn. Generic instructions are available here https://eduvpn.tuni.fi/vpn-user-portal/documentation for various OS, but, for example, Ubuntu is described below.</p> <p>Install OpenVPN:</p> <pre><code>~$ sudo apt-get install network-manager-openvpn-gnome\n</code></pre> <p>Generate your own at https://eduvpn.tuni.fi/vpn-user-portal/configurations (give name, e.g., \"joni-laptop\", and store somewhere).</p> <p>Start openvpn:</p> <p><pre><code>~$ sudo openvpn &lt;PATH_TO_MY_GEN_CONFIG&gt;.ovpn\n</code></pre> And that's it - your internet connection goes over VPN and you have access to university computers!!</p> <p>Note: You need to update the VPN configuration files every now and then (the expriry date by default is in the filename, e.g., \"Downloads/eduvpn.tuni.fi_internet_20201102_joni-laptop.ovpn#)</p>"},{"location":"Technical-Notes/install-tuni-vpn/#update-on-the-linux-desktop-client-of-eduvpn","title":"Update on the Linux desktop client of eduVPN:","text":"<p>There is a Linux desktop client and Python API for eduVPN and here is the link to that: https://python-eduvpn-client.readthedocs.io/en/master/introduction.html#installation</p> <p>I tested it on Ubuntu 18.04 and 20.04 and it works fine. The steps are simple and listed below (taken from the above documentation link).  <pre><code>$ sudo -s\n$ apt install apt-transport-https curl\n$ curl -L https://repo.eduvpn.org/debian/eduvpn.key | apt-key add -\n$ echo \"deb https://repo.eduvpn.org/debian/ stretch main\" &gt; /etc/apt/sources.list.d/eduvpn.list\n$ apt update\n$ apt install eduvpn-client\n</code></pre> Open the eduvpn-client from the terminal (or app launcher) and add the university name from the drop-down menu. They may ask you to sign-in with the TUNI username. Then select the university name and toggle the connected button. If it does not work then you are on your own. </p>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/","title":"Best Practices, Tips and Tricks for SAUNA Machines","text":"<p>This wiki page is a collection of tips and tricks, but also best practices for using the SAUNA machines. If you have a tip or trick that you would like to share, please add it to this page. If you are looking for a way to connect to SAUNA machines, please see the guide for setting up the remote access.</p>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#storage","title":"Storage","text":"<p>General idea of different disks</p>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#ssd-boot-disk","title":"SSD: boot disk","text":"<ul> <li>New machines have a partition of NVMe as boot disk</li> <li>Contains<ol> <li>root (/) dir</li> <li>/home dir</li> <li>user\u2019s dir (/home/{user_name})</li> </ol> </li> <li>Good practices:<ol> <li>Store your (small) repos, personal data etc. here, under you own user dir.</li> <li>Do not store data or large files</li> <li>Space is limited and shared between users! Be mindful of that.</li> </ol> </li> </ul>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#nvme-fast-disk","title":"NVMe: fast disk \ud83d\udca8","text":"<ul> <li>Mounted to /home/nvme<ol> <li>Newer machines contain a folder with user\u2019s name where users should place all their data. Keeps everything neat.</li> </ol> </li> <li>Good practices:<ol> <li>Use this disk to run your experiments (and large repos)</li> <li>Use this disk to store your active data</li> <li>Space is limited and shared between users! Be mindful of that.</li> </ol> </li> </ul>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#hdd-storage-disk","title":"HDD: storage disk","text":"<ul> <li>Mounted to /home/hdd<ol> <li>Some machines have multiple HDDs mounted to e.g. <code>/home/hdd1</code> and <code>/home/hdd2</code></li> <li>Newer machines contain a folder with user\u2019s name where users should place all their data. Keeps everything neat.</li> </ol> </li> <li>Good practices:<ol> <li>Use this disk to store (inactive) data.</li> <li>Space is limited and shared between users! Be mindful of that.</li> </ol> </li> <li> <p>Create folders with your own name and accumulate files under these! (If not done already)</p> <pre><code>cd /home/nvme\nsudo mkdir ilpo\nsudo chown ilpo ilpo/\n</code></pre> </li> <li> <p>Now you can create files under this folder</p> </li> </ul>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#upgrading-and-updating-the-machines","title":"Upgrading and Updating the Machines","text":""},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#updating","title":"Updating","text":"<p>\u2757 Every user is responsible to keep their machines up to date \u2757</p> <p>Every now and then, the machines need to be updated and upgraded. This is done by running the following commands:</p> <pre><code>sudo apt update\nsudo apt upgrade\nsudo apt autoremove\n</code></pre>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#upgrading-the-linux-version","title":"Upgrading the Linux version","text":"<p>\u2757 Do not do this if you are not certain of your actions \u2757</p> <p>When you should upgrade the Linux version?</p> <ul> <li>When you are certain that you need a newer version of the Linux kernel (e.g. for a specific feature or a package)</li> <li>When support for the current LTS version is ending. LTS versions are supported for 5 years, but after that, you should upgrade to a newer version since older ones are not getting security updates. \u27a1\ufe0f Support for Ubuntu 18.04 LTS ends in April 30th 2023. After that, you should upgrade to Ubuntu 20.04 LTS or newer.</li> </ul> <p>If you are certain that you want to upgrade the Linux version, you can follow these steps:</p> <ol> <li> <p>Backup your data! This is important since the upgrade process can fail and you might lose your data.</p> </li> <li> <p>Check that you have the latest updates installed</p> <pre><code>sudo apt update\nsudo apt upgrade\nsudo apt autoremove\n</code></pre> </li> <li> <p>Do a reboot</p> <pre><code>sudo reboot\n</code></pre> </li> <li> <p>Check that you have screen installed. If your SSH connection is lost during the upgrade, screen will allow you to continue the upgrade from where you left off. Upgrade process will start a screen session automatically.</p> <pre><code>sudo apt install screen\n</code></pre> </li> <li> <p>Install Ubuntu update tool</p> <pre><code>sudo apt install update-manager-core\n</code></pre> </li> <li> <p>Make sure you can SSH to port 1022. Addittional sshd will be started on port 1022. If something goes wrong, you can still connect to the machine and continue the upgrade.</p> <pre><code>sudo ufw allow 1022/tcp\n</code></pre> </li> <li> <p>Start the upgrade</p> <pre><code>sudo do-release-upgrade\n</code></pre> </li> <li> <p>Reboot the machine</p> <pre><code>sudo reboot\n</code></pre> </li> </ol>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#additional-resources","title":"Additional resources","text":"<ul> <li>Here is a nice guide for upgrading Ubuntu 18.04 LTS: How to Upgrade Ubuntu 18.04 to 20.04.</li> <li>How to reattach to the screen session if your SSH connection is lost: See this serverfault post.</li> </ul>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#development-environments","title":"Development Environments","text":""},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#miniconda-python","title":"Miniconda (Python)","text":"<p>Please see this video if you are unfamiliar with Conda:</p> <p>The only CONDA tutorial you'll need to watch to get started (YouTube)</p> <ul> <li>Miniconda is installed per user!</li> <li> <p>Install via terminal:</p> <p>Installing on Linux \u2014 conda 24.1.3.dev33 documentation</p> </li> <li> <p>Good cheat sheet for commands here</p> </li> </ul> <p>Tip</p> <p>Time to time it is good to clean up the cached packages (there can be a lot of them). You can do it with the following command:</p> <pre><code>conda clean --all\n</code></pre> <p>Tip</p> <p>By default conda environments will be installed to the home directory of the user (<code>~/miniconda3/envs</code>). This is not ideal since the home directory is located on the SSD and the space is limited. Instead, you should install the environments to the NVMe disk, and make a symbolic link to the custom location to easily activate such environment. Here is how you can do it:</p> <pre><code># Create environment\nconda create --prefix /home/nvme/$USER/.envs/$MY_ENV python=3.9\n# Create symbolic link\nln -s /home/nvme/$USER/.envs/$MY_ENV ~/miniconda3/envs/$MY_ENV\n# Activate environment\nconda activate $MY_ENV\n</code></pre>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#vscode","title":"VSCode","text":"<p>Install VSCode to the client machine (your laptop) and use the Remote - SSH extension to connect to the SAUNA machines. This way you can use the full power of the SAUNA machines while having a nice development environment on your laptop. See the guide how to connect to a remote host from VSCode. It is recommended that you first add SAUNA machine to your SSH config file. See the tip under How to setup client-section.</p>"},{"location":"Technical-Notes/sauna-machines-tips-and-tricks/#adding-new-sudo-users","title":"Adding New Sudo Users","text":"<ol> <li> <p>First add the user</p> <pre><code>sudo adduser new_user\n</code></pre> </li> <li> <p>Add the user to the sudo group</p> <pre><code>sudo adduser new_user sudo\n</code></pre> </li> <li> <p>Create folders for the user</p> <pre><code>cd /home/nvme\nsudo mkdir new_user\nsudo chown new_user new_user/\n\ncd /home/hdd\nsudo mkdir new_user\nsudo chown new_user new_user/\n</code></pre> </li> <li> <p>Share the username and password with the new user. Tell them to change the password after the first login.</p> </li> </ol>"},{"location":"Technical-Notes/tuni-tcsc-cluster/","title":"TUNI TCSC Cluster","text":"<p>This guide is based on similar one made for the previous TUNI cluster Narvi and can be found from X Files of this Wiki (TUNI Narvi Cluster)</p> <p>This document describes how to use the <code>TUNI TCSC</code> computing cluster.</p> <p>What is TCSC?</p> <ul> <li>Narvi is the SLURM cluster that substituted the old Narvi cluster in 2025 (that replaced even older Merope cluster in 2017).</li> <li>The cluster is used by researchers, faculty members, and students at Tampere University.</li> <li>There are powerful CPU-only (e.g. Xeon) and GPU nodes (e.g. 4xV100 and 8xH200) - details about available resources can be found from the TCSC Web page.</li> </ul>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#how-to-get-an-account","title":"How to Get an Account?","text":"<p>The user rights are granted per research team and maintained by the team leader (PI). Details about obtaining the rights is found from TUNI Intranet and it can take several days.</p> <p>Once you have the accounts ready, you can access the computing resources through a dedicated Web interface or old-fashioned using terminal with ssh. Note that outside the campus network VPN connectin can be needed.</p>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#how-to-check-the-queue","title":"How to Check the Queue","text":"<p>To see the status of the queue, type <pre><code>squeue\n# for a specific partitions (e.g. `test`).\nsqueue -p test\n# for a specific user\nsqueue -u &lt;user&gt;\n</code></pre></p> <p>Available job queues are listed in the internal TCSC wiki (access is limited).</p>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#how-to-run-a-job","title":"How to Run a Job","text":"<p>Remember: do not use the login node for computation \u2013 it is slow and will degrade the performance of the login node for other users!</p> <p>There are two common ways to run a job at a <code>slurm</code> cluster:</p> <ul> <li><code>srun</code></li> <li><code>sbatch</code></li> </ul> <p>The main difference is that <code>srun</code> is interactive which means the terminal will be attached to the current session. The experience is just like with any other command in your terminal. Note, that when the queue is full you will have to wait until you get resources.</p> <p>If you use <code>sbatch</code>, you submit your job to the slurm queue and get your terminal back; you can disconnect, kill your terminal, etc. with no consequence. In the case of <code>srun</code>, killing the terminal would kill the job. Hence, <code>sbatch</code> is recommended.</p> <p>Here is the example <code>srun</code> command which will ask the cluster to start an interactive shell with 1 GPU (<code>--gres</code>) and 10 CPUs (<code>--cpus-per-task</code>), 10 GB of RAM (<code>--mem-per-cpu</code>) that will be available to you for 30 minutes (<code>--time</code>): <pre><code>srun \\\n    --pty \\\n    --job-name pepe_run \\\n    --partition gpu \\\n    --gres gpu:1 \\\n    --mem-per-cpu 1G \\\n    --ntasks 1 \\\n    --cpus-per-task 10 \\\n    --time 00:30:00 \\\n    /bin/bash -i\n</code></pre></p> <p>and this is an example <code>sbatch</code> command which will ask the cluster to run <code>my_script.sh</code> with 1 GPU and 10 CPUs, 10 GB of RAM that will run for at most 30 minutes (if the script has finished execution the job will be ended), the output and error logs will be saved to <code>log_JOBID.txt</code> (<code>--output</code>, <code>--error</code>): <pre><code>sbatch \\\n    --job-name pepe_run \\\n    --partition gpu \\\n    --gres gpu:1 \\\n    --mem-per-cpu 1g \\\n    --ntasks 1 \\\n    --cpus-per-task 10 \\\n    --time 00:30:00 \\\n    --output log_%j.txt \\\n    --error log_%j.txt \\\n    my_script.sh\n</code></pre> you may also use <code>--constraint='kepler|pascal|volta'</code> in order to select a specific gpu architecture.</p> <p>Instead of specifying the resources and other information as command-line arguments, you may find it useful to list them inside of <code>my_script.sh</code> and then just use <code>sbatch my_script.sh</code>: <pre><code>#!/bin/bash\n#SBATCH --job-name=pepe_run\n#SBATCH --gres=gpu:1\n#SBATCH --time=00:30:00\n# and so on. To comment SBATCH entry use `##SBATCH --arg ...`\n# here starts your script\n</code></pre></p> <p>To learn more <code>sbatch</code> hacks, a reader is also referred to this nice tutorial.</p>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#how-to-cancel-my-job","title":"How to Cancel My Job","text":"<p>To cancel a specific job you are running, use <pre><code>scancel &lt;JobID&gt;\n</code></pre></p>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#how-to-transfer-data","title":"How to Transfer Data?","text":"<p>The simplest way is to use <code>scp</code> command <pre><code>scp -r ./folder user@xxxx.tuni.fi:/my/path/\n</code></pre> where <code>-r</code> means to copy the folder with all files in it.</p> <p>However, once the internet connection is interrupted you will need to start all over again. To have an opportunity to resume the data transfer try <code>rsync</code> instead <pre><code>rsync -ahP ./folder user@xxxx.tuni.fi:/my/path/\n</code></pre> where <code>-ah</code> means to preserve permissions symlinks, etc as in the original folder and <code>h</code> makes the progress \"human-readable\", and <code>P</code> allows to continue data transfer (sends missing files on the target path \ud83e\udd13).</p> <p>Trailing <code>/</code> in <code>rsync</code> makes the difference</p> <ul> <li><code>rsync /dir1/dir2/ /home/dir3</code> - copies the contents of <code>/dir1/dir2</code> but not the <code>dir2</code> folder itself.</li> <li><code>rsync /dir1/dir2 /home/dir3</code> \u2013 copies the folder <code>dir2</code> along with all its contents.</li> </ul> <p>If you would like to see the files from a remote machine you may mount the folder locally. On Ubuntu/Debian install <code>sshfs</code> and run this <pre><code>mkdir narvi_folder\nsshfs user@xxx.tuni.fi:/my/folder/ ./my_folder\n</code></pre> the content of the <code>/my/folder</code> will be shown in <code>./my_folder</code>. Mind that the changes in either folder will be reflected in another one.</p> <p>To unmount the folder use <pre><code>umount ./my_folder\n</code></pre></p>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#how-do-i-install-my-software","title":"How Do I Install My Software","text":""},{"location":"Technical-Notes/tuni-tcsc-cluster/#slurm-modules-best-option","title":"Slurm modules (best option)","text":"<p>Before you install own software, check if the software you would like to install is already installed by the admin (e.g. matlab, cuda, and gcc). These are set up using <code>module</code> functionality. You can load a module by specifying <code>module load &lt;mod&gt;</code> inside of your script. To see all available modules run <code>module avail</code>.</p> <p>Examples are given in the TCSC internal Wiki, and a good tutorial is provided by CSC in their Slurm Modules tutorial slide set.</p> <p>If you are not satisfied with the selection you can install your own. Below are several options how to do that.</p>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#using-conda-avoid-if-you-can","title":"Using Conda (avoid if you can)","text":"<p>Conda allows you to</p> <ul> <li>Fully control what software packages are installed</li> <li>Have own environments for different projects</li> <li>Copy environments from your computer to a TCSC computing node</li> </ul> <p>However, using conda is not recommended since</p> <ul> <li>Problems to use together with Slurm modules</li> <li>sbatch startup can be slow - read more from CSC best practices for Conda</li> </ul> <p><code>conda</code> Has Many Linux Tools</p> <p>Besides a ton of <code>Python</code> packages, <code>conda</code> has surprisingly many common Linux tools, e.g. <code>tmux</code>, <code>htop</code>, <code>ffmpeg</code>, <code>vim</code>, and more. This is especially useful if you would like to install them but do not have <code>sudo</code> rights.</p>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#creating-a-conda-environment","title":"Creating a <code>conda</code> Environment","text":"<p>Minimal Conda is available in the miniforge package, log in the tcsc computer and load the module <pre><code>module load miniforge3/24.9.0\n</code></pre></p> <p>Let's start by creating an empty conda environment <pre><code>conda create --name my_env\n</code></pre></p> <p>Activate it (meaning that all binaries installed in this environment will be used instead of the system-wise packages) <pre><code>conda activate my_env\n# if it didn't work try `source activate my_env`\n</code></pre></p> <p>Afterward, you can install <code>conda</code> packages <pre><code>conda install python pip matplotlib scikit-learn\n</code></pre></p> <p>If default <code>conda</code> channels don't have some package you search for other <code>conda</code> channels: <pre><code>conda install dlib --channel=menpo\n</code></pre></p> <p>If your favorite package is not available anywhere in <code>conda</code> OR you would like to install <code>OpenCV</code>, try to install it via <code>pip</code>: <pre><code># check if you are using the `pip` from your `conda` env\nwhich pip\npip install opencv-python\n</code></pre></p> <code>conda</code> vs <code>pip</code> inside of <code>conda</code> env? <p>According to official anaconda documentation, you should install as many requirements as possible with <code>conda</code>, then use <code>pip</code>. Another problem with <code>pip</code> packages inside of <code>conda</code> is associated with poor dependence handling and just bad experience when trying to replicate the same environment on another machine.</p> <p>Alternatively, if you have an existing Conda environment for your code, it can be exported <pre><code>conda activate my_env\nconda env export &gt; my_env.yml\n</code></pre> The yml file is transferred to the TCSC computer where it can be used to install the same environment: <pre><code>module load miniforge3/24.9.0\nconda env create -f my_env.yml\n# This can take long\nconda activate my_env\n</code></pre></p> <p>Several guides could be useful:</p> <ul> <li>Problems to run Conda with sbatch - Activating Conda Environments from Scripts: A Guide for Data Scientists</li> <li>Conda best practices for CSC supercomputers</li> </ul>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#using-conda-and-existing-modules-better-than-only-conda","title":"Using Conda and existing modules (Better than only Conda)","text":"<p>Someone must write</p>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#using-python-virtual-environment","title":"Using Python virtual environment","text":"<p>Someone must write</p>"},{"location":"Technical-Notes/tuni-tcsc-cluster/#using-containers","title":"Using containers","text":"<p>Someone must write</p>"},{"location":"Technical-Notes/version_control/","title":"Version Control","text":"<p>It is important that all your source code and documents are in version control since one day your computer will break down and that day you will thank yourself having them under version control. There are many other reasons, but that is the day when it really pays off.</p> <p>Below are instruction for various different purposes.</p>"},{"location":"Technical-Notes/version_control/#personal-version-control-using-university-ssh-servers","title":"Personal version control using university ssh servers","text":"<p>This is what you should do for your personal documents, such as CV, job applications, list of publications, love letters etc. that you feel uncomfortable to put on public servers such as GitHub, but that you wish to be safe, versioned and backup.</p> <p>For that purpose the university ssh servers and Subversion provide suitable tools. First, connect id.tuni.fi and obtain rights to use these services: \"manage your user rights\" -&gt; \"My user rights\" -&gt; \"Apply for a new user right\" -&gt; Choose student or staff contract -&gt; \"IT\" -&gt; \"Linux Servers\". Wait a few minutes and you should access to the servers.</p> <p>Create personal repository:</p> <pre><code>$ ssh linux-ssh.tuni.fi\n$ mkdir svn_repos; cd svn_repos\n$ mkdir &lt;personal_dir&gt;\n$ svnadmin create /home/&lt;my name&gt;/svn_repos/&lt;personal_dir&gt;\n</code></pre> <p>Now the repository is created and you can access it from your personal computer. First take out the repo:</p> <pre><code>$ cd Work\n$ svn co svn+ssh://&lt;my name&gt;@linux-ssh.tuni.fi/home/&lt;my name&gt;/svn_repos/&lt;personal_dir&gt;\n</code></pre> <p>Now you have personal repository that is stored and backup in the university system. SVN (Subversion) is pretty similar to Git, but simpler. For example, you don't \"push\" and \"pull\", but use \"svn commit\" to add you changes and \"svn update\" to update changes to the existing repository. </p> <p>A Fine SVN BOOK is available here http://svnbook.red-bean.com/</p>"},{"location":"Technical-Notes/version_control/#research-project-code-and-documents-in-github","title":"Research project code and documents in Github","text":"<p>Someone needs to write.</p>"},{"location":"Technical-Notes/wifi/","title":"Wireless connections","text":"<p>If you are tired to use your phone as a wifi hotspot you may try one of the university wireless networks.</p>"},{"location":"Technical-Notes/wifi/#tuni-staff","title":"TUNI-STAFF","text":"<p>Works in Windows and centrally maintained Linux boxes, but clearly making it available to self-maintained Linux boxes was beyond their skills. Do not try.</p>"},{"location":"Technical-Notes/wifi/#eduroam","title":"Eduroam","text":"<p>Eduroam provides access in many universities world wide and is also easiest wireless connection in TUNI premises.</p> <p>Easiest way to install Eduroam is to download a domain specific installation script  from https://cat.eduroam.org/ . Just follow the instructions and that's it!</p>"},{"location":"University-Bureaucracy/cs_curricula/","title":"Computing Sciences Curricula","text":"<p>The BSc and MSc degrees offered by Computing Sciences consist of 1) mandatory courses for everyone and 2) major module and 3) minor module(s). Below are details of each degree program offered by Computing Sciences.</p> <p>Below are links to relevant information in TAU Web pages:</p> <ul> <li>Search all courses, modules and programs of Tampere University (Note: language setting affects the search results)</li> </ul>"},{"location":"University-Bureaucracy/cs_curricula/#signal-processing-and-machine-learning-bsc-in-technology-finnish-program-30-cr-thesis","title":"Signal Processing and Machine Learning BSc in Technology (Finnish program, 30 cr + thesis)","text":"<p>The Signal Processing and Machine Learning (SPML) major is offered in the Bachelor of Science and Technology degree program of the Computing and Electrical Engineering. Our graduates are some of the most wanted in Finnish IT and EE companies and research institutions. The SPML major consists of three mandatory courses (tot 15 cr) and 15 cr from elective courses that can be selected from the list of suggested courses or by proposing a personal study plan.</p> <p></p>"},{"location":"University-Bureaucracy/cs_curricula/#signal-processing-and-machine-learning-msc-in-technology-finnish-program-30-cr-thesis","title":"Signal Processing and Machine Learning MSc in Technology (Finnish program, 30 cr + thesis)","text":"<p>Similar to our BSc program the MSc program also consists of two mandatory courses (10 cr) and then the student is encouraged to pick one of our three special sub-modules focusing on Audio, Vision or Artificial Intelligence. Since some of these sub-modules contain one shared course that course is moved to elective module.</p> <p></p>"},{"location":"University-Bureaucracy/employee/","title":"Make a work contract request","text":"<p>As a supervisor you need to confirm contracts to your group memers. For contracts send email to <code>itc-hr.tau at tuni.fi</code>. You need to mention:</p> <ul> <li>The period of contract (e.g. Jan 1 2021 - Dec 31 2021)</li> <li>The salary level (e.g. \"Starting PhD student\")</li> <li>Whether contract is full time (100%) or part-time</li> <li>From which project the salary is paid</li> </ul> <p>Also include the following persons to your email:</p> <ul> <li>Your controller</li> <li>Project leader (if not you)</li> </ul>"},{"location":"University-Bureaucracy/msc_thesis/","title":"MSc Thesis","text":"<p>MSc thesis project typically takes 5-8 months of full-time work. It includes reading papers and books related to your work, implementing or adapting existing code and methods, testing them, and finally writing the thesis manuscript.</p> <p>The thesis is about marketing yourself and therefore you should impress yourself, your family, your supervisors, and your future employer.</p> <p>It is advisable to produce Github pages for your code and data with nice Wiki how to replicate the results and link to the thesis PDF. Its even better if the page also contains a Youtube video of your amazing work. A good example is, for example, Lauri's personal page.</p>"},{"location":"University-Bureaucracy/msc_thesis/#stage-1-find-a-topic","title":"Stage 1 - Find a topic","text":"<p>At least 6 months before finishing all your courses you must start looking for  a job where you can do your thesis. Most MSc theses in Finland are done in companies so seek for any open junior position and they will understand that you need to write a thesis.</p> <p>To make something meaningful that benefits your career,  1) do thesis about something meaningful and difficult so that you learn new, 2) do it so well that it will impress people who pay your salary.</p> <p>You could contact your professors and ask them for open topics in their research groups (paid and unpaid positions are available) or if they know any companies who are looking for a master's thesis worker. Be active and search until you find a place that suits you and you suit that place.</p>"},{"location":"University-Bureaucracy/msc_thesis/#stage-2-agree-about-the-topic-with-your-supervisors","title":"Stage 2 - Agree about the topic with your supervisors","text":"<p>Important: You need to understand what should be done in this thesis! You need to understand why this is an important topic (motivates that it needs to be done)! You must understand how to evaluate your results (otherwise it will be unclear what is the quality of your work).</p> <p>You should have two supervisors: 1) Academic supervisor who is a senior staff from university (professor, associate/assistant professor, lecturer etc. someone with doctoral degree) and 2)  a technical supervisor from the company you work for (preferably someone with at least MSc degree so that they know what MSc thesis is all about). You may interview multiple professors to find who is the most suitable for you. You know, there is a huge difference between supervisors and how much they have time and interest for you.</p> <p>Company pays your salary so you must make your technical supervisor to agree what you do, especially if you do the work during your working hours. You also must know confidential things that cannot be put to your thesis as MSc theses are always public.</p> <p>Concrete action: Read information in MSc thesis Moodle and fill the supervision plan (CS Thesis Moodle.</p>"},{"location":"University-Bureaucracy/msc_thesis/#stage-3-do-the-thesis-project-5-months","title":"Stage 3 - Do the thesis project (~5 months)","text":"<p>Important: There are three important things to bear in mind: 1) read what others have done (related work), 2) read what others have done (related work) and finally 3) read what others have done (related work).</p> <p>Before you can find the related works you must know the correct terminology of your problem! Only with the correct terms search engines (Google, you.com) can provide correct links to the existing code, articles and books.</p> <p>Steps:</p> <ul> <li>Find correct terminology (e.g. \"face verification\" vs. \"face recognition\" vs. \"face detection\")</li> <li>Search related works under this terminology - prefer recent works that have been published in good journals and conferences (ask your supervisor) and have been cited by others.</li> <li>Search existing code you can use</li> <li>Search existing data you can use</li> <li>Play with code and data to get your hands dirty</li> <li>Based on findings revise your topic and thesis plan</li> </ul> <p>Work hard, be diligent and consult your supervisors often! Yes, talking with your supervisors is your responsibility, not theirs.</p>"},{"location":"University-Bureaucracy/msc_thesis/#stage-4-write-thesis-1-month","title":"Stage 4 - Write thesis (~1 month)","text":"<p>This can happen parallel during stage 3, and its good to make notes all the time.</p> <p>Check out this Latex template: MSc thesis template (Latex)</p> <p>Examples of great theses (although your main supervisor may have different examples so ask him/her):</p> <ul> <li>Frans Murto (2024 - made at Bitwise): Real-time expected possession value estimation in ice hockey</li> <li>Valtteri Kaatrasalo (2022 - made at Uni): Computer vision methods for augmented reality</li> <li>Atakan Dag (2021 - made at Uni): Comparison of monolithic and hybrid controllers for multi-objective sim-to-real learning</li> <li>Eero Hein\u00e4nen (2018 - made at OptoFidelity): A Method for automatic tuning of PID controller following Luus-Jaakola optimization</li> </ul> <p>Actions: You must attend the MSc thesis seminar course of you major. The seminar typically includes: 1) watching MSc presentations by others, 2) presenting your work (at least once, agree this with your supervisor); and 3) participating information literacy training by university Library. All details you will find from the course Moodle page or ask from the seminar course instructor.</p>"},{"location":"University-Bureaucracy/msc_thesis/#stage-5-submitting-the-thesis","title":"Stage 5 - Submitting the thesis","text":"<p>You must ask your academic supervisor comments for your thesis. Some supervisors comment multiple versions the manuscript, but some only the final draft i.e. the version that you think is pretty much ready. Ask your supervisor(s) what he/she prefers. Remember that you are evaluated every time you send something to your supervisor!</p> <p>After the supervisors are happy to the current version:</p> <ul> <li>Submit thesis to Turnitin originality test (your supervisor's Moodle space) official instructions</li> <li>After the Turnitin  if fine, then submit the final version to Trepo and let your supervisor know it is there for his/her evaluation official instructions</li> </ul> <p>Evaluation criteria and evaluation templates can be found from thise official page</p>"},{"location":"University-Bureaucracy/msc_thesis/#freedom","title":"Freedom","text":"<p>Enjoy your life, You deserve good life!</p> <p>However, keep updating your knowledge so that your knowledge and skills remain current for the future jobs and needs!</p>"},{"location":"University-Bureaucracy/phd_thesis/","title":"PhD Thesis","text":"<p>So, you decided that doing a PhD thesis is good for your future. Along the long and winding road you may find the following instructions useful.</p>"},{"location":"University-Bureaucracy/phd_thesis/#stage-0-find-supervisor-and-apply-for-doctoral-studies-year-0","title":"Stage 0 - Find supervisor and apply for doctoral studies (year 0)","text":"<p>You must be absolutely sure that you want a PhD degree since it means four years of super heavy work under (possibly) monstrous supervisor. On the positive side, you will learn how to make science and that opens the door to the academic career. In addition, many R&amp;D labs of big companies appreciate PhD degree from their employees.</p> <p>In order to apply you need to fill and submit a number of super boring bureaucratic forms that insist your commitment and also commitment from your main supervisor (make sure you found a good one):</p> <ul> <li>Forms to be submitted for doctoral studies</li> </ul> <p>Before applying send an email to doctoral studies office and ask for the list of things to be submitted and a link to the electronic application system.</p> <p>Welcome, you just started your jorney toward magic of science.</p>"},{"location":"University-Bureaucracy/phd_thesis/#stage-1-do-research-years-1-4","title":"Stage 1 - Do research (years 1-4)","text":"<p>Input: 1) you, 2) your supervisor, and 3) funding for your salary and research.</p> <p>This is the most challenging part, but don't worry, your supervisor will tell you all the necessary details and tricks. However, you may find the following links helpful or at least fun to read:</p> <ul> <li>A Survival Guide to a PhD by Andrej Karpahty</li> <li>How to do research by Bill Freeman</li> <li>Scientific article writing by Fredo Durand</li> </ul> <p>Output: Novel scientific knowledge. More concretely, a number of peer-reviewed scientific articles.</p>"},{"location":"University-Bureaucracy/phd_thesis/#stage-2-write-the-thesis-manuscript-year-4","title":"Stage 2 - Write the thesis manuscript (year 4)","text":"<p>Input: Sufficient amount of scientific contributions, typically in the terms of the articles from the previous stage.</p> <p>It is difficult to tell a generic rule when you're ready to start writing your thesis as that varies a lot between the fields, even between fields close to each other. You should discuss with your supervisor each year what is the stage of your PhD studies and she/he certainly tells you when it is time to start writing.</p> <p>There are recommendations for PhD thesis from DPCEE. It is worth to read through and perhaps adopt their structure, but of course you should follow practices in your field and discuss with your supervisor. However, it seems that the committee provides a lot of feedback if you do not follow these recommendations.</p> <p>Before writing you need a suitable template. Vast majority of people prefer Latex as it is just so convenient for writing scientific text.</p> <ul> <li>A popular template is provided by Ville Koljonen: https://www.overleaf.com/read/zskzfgpnpjcz</li> </ul> <p>Output: A thesis manuscript that summarizes your research and results. The thesis can be a monograph or a compilation thesis that includes your original articles. Write using a meaningful structure and beautiful grammar and send it for comments to your supervisor(s) before proceeding to the next stage.</p>"},{"location":"University-Bureaucracy/phd_thesis/#stage-3-pre-examination","title":"Stage 3 - Pre-examination","text":"<p>Input: Final draft of thesis and fixed using the comments from your supervisor. The pre-examination form.</p> <p>Your supervisor selects two reviewers, makes sure they are available and willing and fills out the official form (see below). You need to send the following two documents to your doctoral program academic officer (contact details and submission deadlines):</p> <ol> <li>The \"proposal of pre-examiners\" form filled (ask your supervisor to help).</li> <li>PhD thesis in PDF format. If a compilation thesis, then it should include the articles. Make a single PDF and if its size &gt;15MB you should downscale your images before compiling the PDF</li> </ol> <p>You may also want to read general guidelines from the university.</p> <p>Your documents will be processed by the Faculty council (they meet ~once a month) and you will receive an email notification once this is done. Your pre-examiners will also receive a formal invitation and the submitted PhD thesis. Now you cross your fingers, wait for two months and hope for positive reviews. Time to think about what you will do next in your life and perhaps start to look for a position in academia or industry!</p> <p>Also, start taking care of your ECTS. Once you are done, send an email to the academic officer and ask if everything is ok.</p> <p>Output: Faculty council decision for pre-examination. Official invitations to the pre-examiners.</p>"},{"location":"University-Bureaucracy/phd_thesis/#stage-4-apply-for-permission-to-defend-and-publish-the-thesis","title":"Stage 4 - Apply for permission to defend and publish the thesis","text":"<p>Input: positive statement from the pre-examiners. Form to publish the thesis.</p> <p>You are almost done. Next, you need just a little bit of planning. Now, you pick a date for your defence (a Friday but other days are also possible) and, if the defence is in person, book the room (via campus assistants - go to an info-desk/reception or find their email). Your supervisor selects 1-2 opponents who will come and publicly \"torture\" you, i.e. ask nasty questions about your thesis.</p> <p>Submit the following documents to the Academic Officer of your doctoral program (contact details and submission deadlines):</p> <ol> <li>The \"Application to apply the right to publish the dissertation\" form.</li> <li>The \"Proposal of opponent(s), custos and the public defence date\" form.</li> <li>The final version of your thesis.</li> <li>A document describing the changes requested by the pre-examiners (if requested) -- see the bottom of the \"Application to apply the right to publish the dissertation\" form. This document is similar to the \"Revision letter\" where you reply to reviewers' comments if they requested \"major revision\" for your article. If necessary discuss with your supervisor how to do these.</li> </ol> <p>You also need to publish your thesis, i.e. make it publicly and openly available. The official permission comes from the Faculty council (~1-2 weeks after the document submission deadline), but meanwhile, you can already proceed with the next steps to save time if you feel that you will get the permission to print (e.g. reviewers didn't raise major concerns etc). Contact the library and start doing their 9-step checklist (see the bottom right) as you are waiting for permission to print and defend.</p> <p>After the Faculty council informs you that the permission to publish is granted, notify the library so they could publish your thesis in Trepo and the printing house so they will print you the physical copy. Tell your supervisor to send the link to the thesis to the opponent(s) -- remember you can't directly contact your opponents.</p> <p>Tip</p> <p>Order at least 5 copies for personal use: your supervisors will probably ask for a signed copy as well as you will need to give/send a copy to each opponent.</p> <p>Output: permission for the public defence, date and room for defence, printed and published manuscript</p>"},{"location":"University-Bureaucracy/phd_thesis/#stage-5-prepare-for-defence","title":"Stage 5: Prepare for defence","text":"<p>Now you should have the date and time of your defence and a booked room. Here are some things you need to do before the defence:</p> <ol> <li>If the defence is in person, ask your supervisor about the dress code and rent the tailcoats if all parties (you, supervisor, opponents) agreed.</li> <li>If in person, make sure to ask campus assistants (and the AV team) to give you a tutorial in the defence auditorium (check the sound on slides etc).</li> <li>If the defence is online, make sure you have tested everything (Zoom, playing sounds during presentation if needed, etc).</li> <li>If the defence is in person, order lunch for you, your opponents, and custos. Also, order cake and coffee for after the defence for participants who were attending in person.</li> <li>Prepare a 15-min presentation for the defence (Lectio Praecursoria).</li> <li>Ask your supervisor to make arrangements for the opponents (hotel, travel, etc).</li> <li>Attend a few defences, follow them online, or watch recordings.</li> <li>In Finland, it is expected to have a \"Karonkka\" dinner after the defence honouring the opponents and others who contributed to your thesis. So, make the necessary arrangements for that. If you don't know about it, search for \"post-defence dinner\" on the Finnish university websites. Also, ask your supervisor and ex-students for expectations and experience in your field.</li> </ol> <p>This stage is stressful but keep calm and carry on.</p> <p>Tip</p> <p>Since you can't contact your opponent directly, but you still want to let them know that you will have the karronka to celebrate your defence, you may ask your supervisor to send them the following: \"May I let (your name) know your dietary preferences for the post-defence dinner?\"</p> <p>Tip</p> <p>You can order two different cakes for the post-defence \"coffee and cake\" event.</p>"},{"location":"University-Bureaucracy/phd_thesis/#stage-6-defence","title":"Stage 6: Defence","text":"<p>This is a formal \"act\" with pre-defined lyrics for custos, candidate and opponents. More details are available on university website.</p> <p>After the defence, your opponents will discuss your grade -- give them time and opportunity to do that on the same day. This report will be submitted to the faculty who will finalize the grading of your thesis. To get the final decision and a grade, you need to wait until the next faculty meeting (deadlines are here).</p> <p>Tip</p> <p>Don't forget your charger for your laptop if the defence is in person!</p>"},{"location":"University-Bureaucracy/phd_thesis/#stage-7-after-the-defence-and-karronka","title":"Stage 7: After the defence and Karronka","text":"<p>Input: successful defence, opponents' report, and a grade.</p> <p>Congratulations! You have done it! The Faculty will contact you regarding the opponents' report which is similar to reviewers' comments.</p> <p>A few touches:</p> <ol> <li>You should send printed books to the opponents (or give them a signed copy before they leave if they attended in person).</li> <li>Apply for graduation in sisu or ask the academic officer for instructions.</li> </ol> <p>Tip</p> <p>You can ask for the recording of your presentation from the AV team if your defence was recorded.</p> <p>Enjoy your life (finally ;-) !</p> <p>Output: degree certificate and freedom</p>"},{"location":"X-Outdated/tuni-narvi-cluster/","title":"TUNI Narvi Cluster","text":"<p>This amazing guide was originally posed in wiki.eduuni.fi and composed by Heikki Huttunen. We obtained his permission to use it here. It was modernized and expanded since then.</p> <p>This document describes how to use the <code>TUNI TCSC Narvi</code> computing cluster.</p> <p>What is Narvi?</p> <ul> <li>Narvi is the SLURM cluster that substituted the old merope cluster in 2017.</li> <li>The cluster is used by researchers, faculty members, and students at Tampere University.</li> <li>There are 140 CPU-only nodes with 3000+ CPU cores</li> <li>Also Narvi has 22 nodes with different GPU nodes with 4 GPUs in each. Specifically, there are<ul> <li>6 nodes with Tesla V100 32 GB and 4 with Tesla V100 16 GB</li> <li>2 nodes with Tesla P100 16 GB and 6 with Tesla P100 12 GB</li> <li>4 nodes with Tesla K80 12 GB</li> </ul> </li> </ul>"},{"location":"X-Outdated/tuni-narvi-cluster/#how-to-get-an-account","title":"How to Get an Account?","text":"<ol> <li>Go to id.tuni.fi</li> <li>Choose <code>Identity management</code> \u2192 <code>My user rights</code> \u2192 <code>Apply for a new user right</code></li> <li>Choose the correct contract (studen/staff).<ul> <li>If you fill the application as a student also tell the Course name and the responsible teacher</li> </ul> </li> <li>Search for <code>Linux Servers (LINUX-SERVERS) TCSC HPC Cluster</code></li> <li>In the form, enter application details: <code>I need Narvi account. My supervisor is X.</code>.</li> <li>Your supervisor will receive an acceptance link and you will be granted a new account.</li> <li>In a few days, you will receive an email from TCSC telling you to send an ssh public key to them. Create a key pair (see below or just google for it) and send the public one to them.</li> <li>Soon you will be able to login to the front end <code>narvi.tut.fi</code> using <code>ssh</code>.</li> </ol> How to generate an <code>ssh</code> key-pair \ud83d\udd10? <p>Here is how to do it on Linux and Mac systems. The instructions for Windows can be easily found on google. <pre><code>ssh-keygen -f ~/.ssh/narvi_key\n</code></pre> The command will ask for a new password which will be asked when this key is used. After, the script will save two keys (<code>narvi_key</code> and <code>narvi_key.pub</code>) in <code>~/.ssh/</code> folder. <code>*.pub</code> is the public key.</p> <p>The first time you will use this key with <code>ssh</code> it may complain about permissions (<code>Permissions are too open.</code>). If so, you will need to change the permissions of the private key <pre><code>chmod 600 ~/.ssh/narvi_key\n</code></pre></p> I don't see any GPU partitions <p>Please write an e-mail to the admin (<code>tcsc.tau@tuni.fi</code>) asking to add you to the GPU group. By default, you will only have access to CPU-only nodes.</p>"},{"location":"X-Outdated/tuni-narvi-cluster/#how-to-check-the-queue","title":"How to Check the Queue","text":"<p>To see the status of the queue, type <pre><code>squeue\n# for a specific partitions (e.g. `normal` or `gpu`).\nsqueue -p gpu\n# for a specific user\nsqueue -u &lt;user&gt;\n</code></pre></p>"},{"location":"X-Outdated/tuni-narvi-cluster/#how-to-run-a-job","title":"How to Run a Job","text":"<p>Remember: do not use the login node for computation \u2013 it is slow and will degrade the performance of the login node for other users!</p> <p>There are two common ways to run a job at a <code>slurm</code> cluster:</p> <ul> <li><code>srun</code></li> <li><code>sbatch</code></li> </ul> <p>The main difference is that <code>srun</code> is interactive which means the terminal will be attached to the current session. The experience is just like with any other command in your terminal. Note, that when the queue is full you will have to wait until you get resources.</p> <p>If you use <code>sbatch</code>, you submit your job to the slurm queue and get your terminal back; you can disconnect, kill your terminal, etc. with no consequence. In the case of <code>srun</code>, killing the terminal would kill the job. Hence, <code>sbatch</code> is recommended.</p> <p>Here is the example <code>srun</code> command which will ask the cluster to start an interactive shell with 1 GPU (<code>--gres</code>) and 10 CPUs (<code>--cpus-per-task</code>), 10 GB of RAM (<code>--mem-per-cpu</code>) that will be available to you for 30 minutes (<code>--time</code>): <pre><code>srun \\\n    --pty \\\n    --job-name pepe_run \\\n    --partition gpu \\\n    --gres gpu:1 \\\n    --mem-per-cpu 1G \\\n    --ntasks 1 \\\n    --cpus-per-task 10 \\\n    --time 00:30:00 \\\n    /bin/bash -i\n</code></pre></p> <p>and this is an example <code>sbatch</code> command which will ask the cluster to run <code>my_script.sh</code> with 1 GPU and 10 CPUs, 10 GB of RAM that will run for at most 30 minutes (if the script has finished execution the job will be ended), the output and error logs will be saved to <code>log_JOBID.txt</code> (<code>--output</code>, <code>--error</code>): <pre><code>sbatch \\\n    --job-name pepe_run \\\n    --partition gpu \\\n    --gres gpu:1 \\\n    --mem-per-cpu 1g \\\n    --ntasks 1 \\\n    --cpus-per-task 10 \\\n    --time 00:30:00 \\\n    --output log_%j.txt \\\n    --error log_%j.txt \\\n    my_script.sh\n</code></pre> you may also use <code>--constraint='kepler|pascal|volta'</code> in order to select a specific gpu architecture.</p> <p>Instead of specifying the resources and other information as command-line arguments, you may find it useful to list them inside of <code>my_script.sh</code> and then just use <code>sbatch my_script.sh</code>: <pre><code>#!/bin/bash\n#SBATCH --job-name=pepe_run\n#SBATCH --gres=gpu:1\n#SBATCH --time=00:30:00\n# and so on. To comment SBATCH entry use `##SBATCH --arg ...`\n# here starts your script\n</code></pre></p> <p>To learn more <code>sbatch</code> hacks, a reader is also referred to this nice tutorial.</p>"},{"location":"X-Outdated/tuni-narvi-cluster/#how-to-cancel-my-job","title":"How to Cancel My Job","text":"<p>To cancel a specific job you are running, use <pre><code>scancel &lt;JobID&gt;\n</code></pre></p>"},{"location":"X-Outdated/tuni-narvi-cluster/#how-to-transfer-data","title":"How to Transfer Data?","text":"<p>The simplest way is to use <code>scp</code> command <pre><code>scp -i ~/.ssh/narvi_key -r ./folder user@narvi.tut.fi:/narvi/path/\n</code></pre> where <code>-r</code> means to copy the folder with all files in it.</p> <p>However, once the internet connection is interrupted you will need to start all over again. To have an opportunity to resume the data transfer try <code>rsync</code> instead <pre><code>rsync -ahP -e \"ssh -i ~/.ssh/narvi_key\" ./folder user@narvi.tut.fi:/narvi/path/\n</code></pre> where <code>-ah</code> means to preserve permissions symlinks, etc as in the original folder and <code>h</code> makes the progress \"human-readable\", and <code>P</code> allows to continue data transfer (sends missing files on the target path \ud83e\udd13).</p> <p>Trailing <code>/</code> in <code>rsync</code> makes the difference</p> <ul> <li><code>rsync /dir1/dir2/ /home/dir3</code> - copies the contents of <code>/dir1/dir2</code> but not the <code>dir2</code> folder itself.</li> <li><code>rsync /dir1/dir2 /home/dir3</code> \u2013 copies the folder <code>dir2</code> along with all its contents.</li> </ul> <p>If you would like to see the files from a remote machine you may mount the folder locally. On Ubuntu/Debian install <code>sshfs</code> and run this <pre><code>mkdir narvi_folder\nsshfs -o IdentityFile=~/.ssh/narvi_key user@narvi.tut.fi:/narvi/folder/ ./narvi_folder\n</code></pre> the content of the <code>/narvi/folder</code> will be shown in <code>./narvi_folder</code>. Mind that the changes in either folder will be reflected in another one.</p> <p>To unmount the folder use <pre><code>umount ./narvi_folder\n</code></pre></p>"},{"location":"X-Outdated/tuni-narvi-cluster/#how-do-i-install-my-software","title":"How Do I Install My Software","text":"<p>Before you do so, check if the software you would like to install is already installed by the admin (e.g. matlab, cuda, and gcc). These are set up using <code>module</code> functionality. You can load a module by specifying <code>module load &lt;mod&gt;</code> inside of your script. To see all available modules run <code>module avail</code>.</p> <p>If you are not satisfied with the selection you can install your own. Here we will focus on <code>Python</code> packages and virtual environment manager <code>conda</code> which is already installed on Narvi (try: <code>which conda</code>).</p> <p><code>conda</code> Has Many Linux Tools</p> <p>Besides a ton of <code>Python</code> packages, <code>conda</code> has surprisingly many common Linux tools, e.g. <code>tmux</code>, <code>htop</code>, <code>ffmpeg</code>, <code>vim</code>, and more. This is especially useful if you would like to install them but do not have <code>sudo</code> rights.</p>"},{"location":"X-Outdated/tuni-narvi-cluster/#creating-a-conda-environment","title":"Creating a <code>conda</code> Environment","text":"<p>Let's start by creating an empty conda environment <pre><code>conda create --name my_env\n</code></pre></p> <p>Activate it (meaning that all binaries installed in this environment will be used instead of the system-wise packages) <pre><code>conda activate my_env\n# if it didn't work try `source activate my_env`\n</code></pre></p> <p>Afterward, you can install <code>conda</code> packages <pre><code>conda install python pip matplotlib scikit-learn\n</code></pre></p> <p>If default <code>conda</code> channels don't have some package you search for other <code>conda</code> channels: <pre><code>conda install dlib --channel=menpo\n</code></pre></p> <p>If your favorite package is not available anywhere in <code>conda</code> OR you would like to install <code>OpenCV</code>, try to install it via <code>pip</code>: <pre><code># check if you are using the `pip` from your `conda` env\nwhich pip\npip install opencv-python\n</code></pre></p> <code>conda</code> vs <code>pip</code> inside of <code>conda</code> env? <p>According to official anaconda documentation, you should install as many requirements as possible with <code>conda</code>, then use <code>pip</code>. Another problem with <code>pip</code> packages inside of <code>conda</code> is associated with poor dependence handling and just bad experience when trying to replicate the same environment on another machine.</p>"}]}